[{"content":"什么是幂等？ 用户对于同一操作发起的一次请求或者多次请求的结果是一致的。\n数据库操作中：SELECT UPDATE DELETE 操作天然就是幂等的，同样的语句执行多次结果都不会产生变化，唯一的就是受影响的行数会变化，但 INSERT 插入操作则不是(在未指定主键或唯一性字段的前提下)；所以需要我们在Java层面保证请求为幂等。否则会出现多次下单、数据异常、扣款重复等情况。闲话少说，说时迟那时快，抄起键盘就是干！\n1、定义一个幂等校验的注解,使用的时候放在需要保证幂等的请求方法上即可。 /** * 标识接口需要保证幂等,未登录接口请勿使用 * @author Jiang Jun */ @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Idempotent { /** * 间隔时间(ms)，小于此时间视为重复提交 */ int interval() default 5000; /** * 提示消息 */ String message() default \u0026#34;不允许重复提交，请稍候再试\u0026#34;; } 2、定义一个拦截器，在 preHandle 方法中做幂等性校验 其中一些我系统本身自定义的类可以替换成你自己工程的类，主要的校验逻辑不受影响，校验是否幂等我采用的判断方式是：使用 Redis 的 String 类型存储请求参数，用户 ID+URI 作为 Key 保证接口请求的唯一性，Value 存储的是本次请求参数的 MD5摘要，MD5担心有的小伙伴不懂我解释一下： MD5 即 Message-Digest Algorithm 5（信息-摘要算法5）常用于文件校验。不管文件多大，经过 MD5 后都能生成唯一的 MD5 值。\n/** * 对方法上标注了幂等请求注解进行幂等校验 * @author Jiang Jun */ @Component public class IdempotentInterceptor implements HandlerInterceptor { @Resource private RedissonClient redissonClient; /** * 防重提交 redis key */ public static final String REPEAT_SUBMIT_KEY = \u0026#34;repeat_submit:\u0026#34;; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (handler instanceof HandlerMethod) { HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); Idempotent annotation = method.getAnnotation(Idempotent.class); if (annotation != null) { // 判断是否为重复提交 if (this.isRepeatSubmit(request, annotation)) { String responseBody = JSON.toJSONString(ResponseResult.error(ErrorCodeEnum.NO_ERROR, annotation.message())); response.setStatus(HttpStatus.OK.value()); response.setContentType(MediaType.APPLICATION_JSON_VALUE); response.setCharacterEncoding(StandardCharsets.UTF_8.name()); response.getWriter().print(responseBody); return false; } } return true; } return true; } /** * 判断是否重复提交 * @param request 请求对象 * @param annotation 幂等注解 * @return 重复提交请求返回true */ private boolean isRepeatSubmit(HttpServletRequest request, Idempotent annotation) throws IOException, NoSuchAlgorithmException { // 用户ID+URI为Redis的Key,请求参数md5摘要为Value String userId = TokenData.takeFromRequest().getUserId(); String uri = request.getRequestURI(); String key = REPEAT_SUBMIT_KEY + userId + uri; RBucket\u0026lt;String\u0026gt; bucket = redissonClient.getBucket(key); // 获取请求体参数 String requestBody = getRequestBody(request); if (StringUtils.isBlank(requestBody)){ requestBody = JSON.toJSONString(request.getParameterMap()); } // redis查询不为null，并且本次的请求参数md5与val相同则为重复请求 if (StringUtils.isNotBlank(bucket.get())){ return bucket.get().equals(jdkMD5(requestBody)); } // 如果redis中没有数据，将本次请求参数存入Redis，考虑到并发情况，trySet 如果已经存在则返回false,代表重复请求 return !bucket.trySet(jdkMD5(requestBody), annotation.interval(), TimeUnit.MILLISECONDS); } /** * 读取请求体内容 */ private String getRequestBody(HttpServletRequest request) throws IOException { return IOUtils.toString(request.getReader()); } /** * MD5摘要并转换为字符串 */ private static String jdkMD5(String str) throws NoSuchAlgorithmException { MessageDigest messageDigest = MessageDigest.getInstance(\u0026#34;MD5\u0026#34;); byte[] mdBytes = messageDigest.digest(str.getBytes()); return DatatypeConverter.printHexBinary(mdBytes); } } 这样校验幂等的工作就完成了，当我感到万事大吉可以潇洒的收起 C V 键帽时。。。又遇到了新的问题：测试的时候 SpringMVC 在解析请求参数转换为我们接收请求参数的实体对象时抛出了一个异常：\njava.lang.IllegalStateException: getReader() has already been called for this request at org.apache.catalina.connector.Request.getInputStream(Request.java:1069) at org.apache.catalina.connector.RequestFacade.getInputStream(RequestFacade.java:365) at com.igg.aggregate.server.aspect.LogAspect.before(LogAspect.java:80)\n原因分析： HttpServletRequest 的 getInputStream() 和 getReader() 都只能读取一次，由于 Request Body 是流的形式读取，那么流读了一次就没有了，所以只能被调用一次。因为我在拦截器中读取了请求体内容，然后 SpringMVC 的参数转换器读取的时候发现已经被读取过了。\n解决办法： 定义一个 RepeatedlyRequestWrapper 类继承 Servlet 自带的 HttpServletRequestWrapper 类，构造方法中先将 Request Body 内容保存在我们重写的 RequestWrapper 的成员属性中，通过覆盖 getReader() 和 getInputStream() 方法，使流从我们自己保存的地方读取。然后使用 Filter 过滤器将原始的 ServletRequest 包装成为 我们自己重写的 RequestWrapper对象。\n3、定义重写后的 RequestWrapper 类 /** * 构建可重复读取inputStream的request * @author Jiang Jun */ public class RepeatedlyRequestWrapper extends HttpServletRequestWrapper { /** * 存放请求体数据 */ private final byte[] body; public RepeatedlyRequestWrapper(HttpServletRequest request, ServletResponse response) throws IOException { super(request); request.setCharacterEncoding(StandardCharsets.UTF_8.name()); response.setCharacterEncoding(StandardCharsets.UTF_8.name()); // 首次读取请求体内容从原生request对象中获取,之后读取都从本对象的重写方法中获取请求体内容 body = IOUtils.toString(request.getReader()).getBytes(StandardCharsets.UTF_8); } @Override public BufferedReader getReader() throws IOException { return new BufferedReader(new InputStreamReader(getInputStream())); } @Override public ServletInputStream getInputStream() throws IOException { final ByteArrayInputStream bais = new ByteArrayInputStream(body); return new ServletInputStream() { @Override public int read() throws IOException { return bais.read(); } @Override public int available() throws IOException { return body.length; } @Override public boolean isFinished() { return false; } @Override public boolean isReady() { return false; } @Override public void setReadListener(ReadListener readListener) { } }; } } 4、定义一个 Filter ，在请求刚进入的时候将 Request 对象转换为我们定义的 RepeatedlyRequestWrapper 至于为什么能转换，看图： /** * 把HttpServletRequest转换为可重复读取的inputStream的request * @author Jiang Jun */ public class RepeatableFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { ServletRequest requestWrapper = null; if (request instanceof HttpServletRequest \u0026amp;\u0026amp; StringUtils.startsWithIgnoreCase(request.getContentType(), MediaType.APPLICATION_JSON_VALUE)) { // 如果是application/json格式的请求体,则将Request转换为可重复读取输入流的形式 requestWrapper = new RepeatedlyRequestWrapper((HttpServletRequest) request, response); } if (null == requestWrapper) { chain.doFilter(request, response); } else { chain.doFilter(requestWrapper, response); } } } 5、将我们的拦截器、过滤器都加入SpringMVC 中使之生效（我使用的 SpringBoot 工程，如您使用的 SSM 请自行百度如何添加） /** * SpringMVC 配置 * @author Jiang Jun */ @Configuration public class WebMvcConfig implements WebMvcConfigurer { @Bean public IdempotentInterceptor idempotentInterceptor(){ return new IdempotentInterceptor(); } @Override public void addInterceptors(InterceptorRegistry registry) { // 添加幂等校验拦截器 registry.addInterceptor(idempotentInterceptor()).addPathPatterns(\u0026#34;/**\u0026#34;); } /** * 此过滤器作用为把HttpServletRequest转换为自定义可重复读取的inputStream的request * 否则在拦截器中读取了请求体中的数据,在参数解析器中无法再次读取 */ @Bean @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34; }) public FilterRegistrationBean someFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new RepeatableFilter()); registration.addUrlPatterns(\u0026#34;/*\u0026#34;); registration.setName(\u0026#34;repeatableFilter\u0026#34;); registration.setOrder(FilterRegistrationBean.LOWEST_PRECEDENCE); return registration; } } 经过以上步骤的准备就可以保证我们的接口是幂等的了，使用方法就是将幂等注解添加到请求方法上即可，开不开心？意不意外？简不简单？（狗头），不足之处是不支持没有任何参数的请求，当然这种请求大多数情况下也不需要保证幂等，另外就是 key 和用户ID绑定了，如果需要解耦可改为在请求幂等接口前后端生成本次请求的唯一请求编号或 Toekn，前端请求的时候带上，实际效果本人已通过 JMerter 并发测试有效，如果有不清晰或者不正确的地方欢迎大佬们留言多多指正！\n","permalink":"https://jiangjun8888.github.io/posts/tech/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E6%80%A7%E6%A0%A1%E9%AA%8C%E6%B3%A8%E8%A7%A3%E5%AE%9E%E7%8E%B0/","summary":"什么是幂等？ 用户对于同一操作发起的一次请求或者多次请求的结果是一致的。 数据库操作中：SELECT UPDATE DELETE 操作天然就是幂等的，同样的语句执行多次结","title":"接口幂等性校验注解实现"},{"content":"CPU 的使用会飙升，一旦飙升，一般怀疑某个业务逻辑的计算量太大，或者是触发了死循环（比如著名的 HashMap 高并发引起的死循环），也有可能是 GC 导致的，如：堆已经满了，但是又没有发生 OOM，于是 GC 进程就一直在那里回收，回收的效果又非常一般，造成 CPU 升高应用假死。\n（1）使用 top 命令，查找到使用 CPU 最多的某个进程，记录它的 pid。使用 Shift + P 快捷键可以按 CPU 的使用率进行排序。\ntop （2）再次使用 top 命令，加 -H 参数，查看某个进程中使用 CPU 最多的某个线程，记录线程的 ID。\ntop -Hp $pid （3）使用 printf 函数，将十进制的 tid 转化成十六进制。\nprintf %x $tid （4）使用 jstack 命令，查看 Java 进程的线程栈。\njstack $pid \u0026gt;$pid.log （5）使用 less 命令查看生成的文件，并查找刚才转化的十六进制 tid，找到发生问题的线程上下文。\nless $pid.log ","permalink":"https://jiangjun8888.github.io/posts/tech/java%E8%BF%9B%E7%A8%8B%E5%AF%BC%E8%87%B4cpu%E8%B4%9F%E8%BD%BD%E8%BF%87%E9%AB%98%E6%8E%92%E6%9F%A5%E6%AD%A5%E9%AA%A4/","summary":"CPU 的使用会飙升，一旦飙升，一般怀疑某个业务逻辑的计算量太大，或者是触发了死循环（比如著名的 HashMap 高并发引起的死循环），也有可能是 GC 导致的，如：堆","title":"Java进程导致CPU负载过高排查步骤"},{"content":"最近工作需要用 Nacos 连接 Oracle 数据库，有两个方案，一个是使用最新版， 添加插件支持，还还一种是使用 Nacos 的多数据源分支，这个分支的 Nacos 版本是 1.4.2-SNAPSHOT，参考文章 ，坑就从这里开始了\u0026hellip;.\n1、故障现象 Error creating bean with name \u0026#39;jpaVendorAdapter\u0026#39; defined in class path resource [org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.orm.jpa.JpaVendorAdapter]: Factory method \u0026#39;jpaVendorAdapter\u0026#39; threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:361) at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:131) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1672) 2、导致原因 我的连接配置是：\nspring.jpa.hibernate.naming.physical-strategy=com.alibaba.nacos.config.server.configuration.NacosPhysicalNamingStrategy nacos.datasource.type=ORACLE nacos.datasource.relational.dsList[0].url=jdbc:oracle:thin:@localhost:1521:ORCL nacos.datasource.relational.dsList[0].username=nacos nacos.datasource.relational.dsList[0].password=123456 nacos.datasource.relational.dsList[0].driver-class-name=oracle.jdbc.driver.OracleDriver nacos.datasource.relational.dsList[0].hikari.connection-timeout=10000 nacos.datasource.relational.dsList[0].hikari.idle-timeout=120000 nacos.datasource.relational.dsList[0].hikari.max-lifetime=240000 nacos.datasource.relational.dsList[0].hikari.maximum-pool-size=20 nacos.datasource.relational.dsList[0].hikari.data-source-properties.cachePrepStmts=true nacos.datasource.relational.dsList[0].hikari.data-source-properties.prepStmtCacheSize=250 nacos.datasource.relational.dsList[0].hikari.data-source-properties.prepStmtCacheSqlLimit=2048 nacos.datasource.relational.dsList[0].hikari.connection-test-query=SELECT 1 FROM dual JVM启动参数设置为：-Dnacos.standalone=true\n点击运行 nacos-feature_multiple_datasource_support/console/src/main/java/com/alibaba/nacos/Nacos.java, 就出现了如上报错，一开始以为是我数据库版本的问题，因为提供的数据库表初始化脚本是12c的，而我安装的是19c,以为是版本不适配的缘故。我用 MySQL 连接的方式测试了一下发现程序可以正常启动，所以猜测问题应该出在连接驱动 Jar 包版本上，但搜索好几篇文章后发现驱动版本是正常的，所以排除，又怀疑问题出在数据库连接信息上，但仔细比对参考的那篇文档后发现并没有错误，于是Debug程序，发现异常是出在通过连接池获取数据库连接上，获取连接失败，但我用其他的数据库连接工具是可以连接上数据库的，于是可排除数据库本身的问题。\n后面想通过 JDBC 的方式测试一下，于是搜索了连接教程，发现 Oracle 的连接字符串还有好几种连接方式，有通过SID的，有通过服务名的，我最初看到的那篇教程是通过 SID 方式，但我的数据库配置的是通过服务名连接，于是修改连接字符串后程序就正常启动了。\nJDBC连接Oracle rac数据库的写法:\n格式一：jdbc:oracle:thin:@//:/\u0026lt;service_name\u0026gt; 格式二：jdbc:oracle:thin:@:: 格式三：jdbc:oracle:thin:@\n格式一是通过 SERVICE_NAME 连接Oracle数据库，适合于单实例和RAC\n格式二是通过实例名SID连接数据库，RAC环境下实例名不唯一，不能充分利用数据库资源\n格式三为通过本地配置的TNSNAME，支持RAC\n这个问题还是由于工作后没有接触过 Oracle 数据库，导致不熟悉出现此问题，特此记录下。\n3、解决方案 将连接 URL 改为：jdbc:oracle:thin:@//:/\u0026lt;service_name\u0026gt; 这种格式，注意这里的格式，port后面:换成了/,这种格式是Oracle 推荐的格式，因为对于集群来说，每个节点的SID 是不一样的，但是SERVICE_NAME 确可以包含所有节点。\n4、参考博客 Oracle JDBC 连接的几种方式\nnacos适配oracle数据库\n[nacos配置Oracle数据源](\n","permalink":"https://jiangjun8888.github.io/posts/tech/nacos%E8%BF%9E%E6%8E%A5oracle%E6%95%85%E9%9A%9C%E8%A7%A3%E5%86%B3/","summary":"最近工作需要用 Nacos 连接 Oracle 数据库，有两个方案，一个是使用最新版， 添加插件支持，还还一种是使用 Nacos 的多数据源分支，这个分支的 Nacos 版本是 1.4.2-SN","title":"Nacos连接Oracle故障解决"},{"content":" 转换符 详细说明 示例 %s 字符串类型 “喜欢请收藏” %c 字符类型 ‘m’ %b 布尔类型 true %d 整数类型（十进制） 88 %x 整数类型（十六进制） FF %o 整数类型（八进制） 77 %f 浮点类型 8.888 %a 十六进制浮点类型 FF.35AE %e 指数类型 9.38e+5 // 补齐空格并右对齐： String.format(\u0026#34;%10s, world\u0026#34;, \u0026#34;Hello\u0026#34;); // 输出 \u0026#34; Hello, world\u0026#34; String.format(\u0026#34;%8d\u0026#34;, 123); // 输出 \u0026#34; 123\u0026#34; // 补齐空格并左对齐： String.format(\u0026#34;%-10s, world\u0026#34;, \u0026#34;Hello\u0026#34;); // 输出 \u0026#34;Hello , world\u0026#34; String.format(\u0026#34;%-8d\u0026#34;, 123); // 输出 \u0026#34;123 \u0026#34; // 补齐 0 并对齐（仅对数字有效） String.format(\u0026#34;%08d\u0026#34;, 123); // 输出 \u0026#34;00000123\u0026#34; String.format(\u0026#34;%-08d\u0026#34;, 123); // 错误！不允许在右边补齐 0 // 输出最多N个字符 String.format(\u0026#34;%.5s\u0026#34;, \u0026#34;Hello, world\u0026#34;); // 输出 \u0026#34;Hello\u0026#34; String.format(\u0026#34;%.5s...\u0026#34;, \u0026#34;Hello, world\u0026#34;); // 输出 \u0026#34;Hello...\u0026#34; String.format(\u0026#34;%10.5s...\u0026#34;, \u0026#34;Hello, world\u0026#34;); // 输出 \u0026#34; Hello...\u0026#34; // 输出逗号分隔数字 String.format(\u0026#34;%,d\u0026#34;, 1234567); // 输出 \u0026#34;1,234,567\u0026#34; 搭配转换符还有实现高级功能\n标志 说明 示例 结果 + 为正数或者负数添加符号 (“%+d”,15) +15 0 数字前面补0(加密常用) (“%04d”, 99) 0099 空格 在整数之前添加指定数量的空格 (“% 4d”, 99) 99 , 以“,”对数字分组(常用显示金额) (“%,f”, 9999.99) 9,999.990000 - 左对齐，不够位数的地方补上空格 (\u0026quot;%-6d\u0026quot;,8) 8 ","permalink":"https://jiangjun8888.github.io/posts/tech/string.format%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","summary":"转换符 详细说明 示例 %s 字符串类型 “喜欢请收藏” %c 字符类型 ‘m’ %b 布尔类型 true %d 整数类型（十进制） 88 %x 整数类型（十六进制） FF %o 整数类型（八进制） 77","title":"String.format方法使用笔记"},{"content":"一、快速迁移方法 1、将 Jenkins 工作目录打包压缩。（因为 Jenkins 的所有配置都存放在工作目录下，所以我们迁移工作目录下的内容即可） 1.1、进入容器挂载的 Jenkins 工作目录，如果没有挂载，则进入容器，默认的工作目录是：/var/jenkins_home。此目录下又两个文件夹占用空间很大，为：./workspace 和 ./caches 第一个是保存的拉取下的代码和编译源文件，第二个是缓存文件，都可以删除掉已节省打包后的文件大小。保险起见先备份到另一个位置再删除。\n1.2、执行命令压缩目录\n#第一个参数为压缩后到文件名，第二个为你要压缩到目录所在位置 tar -cvf jenkins_home.tar /home/data/jenkins_home/ 2、将压缩包迁移至要部署的新机器中，我这用的 scp 命令 scp jenkins_home.tar root@IP地址:/root 1.会提示一段确认信息，输入yes后回车 2.提示输入目标机器登录密码，输入后回车 3、在新机器上启动一个全新的 Jenkins 容器，并挂载好工作目录 #我这是拉取的私人仓库的镜像，如果没有初始镜像的话，可以将最后的镜像名替换为：jenkins/jenkins:latest （来源：DockerHub） docker run -d --privileged=true \\ --name jenkins-hercules -p 8010:8080 -p 50000:50000 \\ --restart=always \\ -v /home/jenkins/data/jenkins_home:/var/jenkins_home \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /usr/bin/docker:/usr/bin/docker \\ -v /etc/localtime:/etc/localtime \\ --user root \\ jenkins-image 4、启动成功后停止容器，删除挂载的工作目录下的所有文件 rm -rf /home/jenkins/data/* 5、将原来压缩好的 Jenkins 工作目录解压至上一步容器挂载的工作目录下 cd /home/jenkins/data/ # 解压至当前目录下 tar -zxvf ~/jenkins_home.tar 6、启动刚刚停止的 Jenkins 容器，用户名和密码都还是原来的，至此迁移完成。 二、完整迁移方法（包含容器） 0、先将工作目录压缩后传到目标机器上，参照上方快速迁移方法的1、2步 1、查看容器运行状态 docker ps -a d796453c4ca1 jenkins:1.0 \u0026#34;/sbin/tini -- /usr/…\u0026#34; 11 months ago Up 6 hours 0.0.0.0:50000-\u0026gt;50000/tcp, :::50000-\u0026gt;50000/tcp, 0.0.0.0:8010-\u0026gt;8080/tcp, :::8010-\u0026gt;8080/tcp jenkins # ps:我这个容器是在在启动jenkins时就把工作目录挂载到宿主机上了，如果没有挂载，请进入容器，默认的工作目录是：/var/jenkins_home。 2、执行 docker commit 命令将容器保存为镜像 docker commit jenkins(容器名) jenkins-image(镜像名) 3、查看镜像 docker images REPOSITORY TAG IMAGE ID CREATED SIZE jenkins-image latest 4a12d5121f83 6 hours ago 3.59GB 4、将镜像保存为压缩文件 docker save docker save -o jenkins.tar（文件名） jenkins-image(镜像名) 5、将压缩好的tar文件移到新机器 #通过 scp 命令直接发送到新机器中，或者push 到 DockerHub 在 Pull到目标机器 #执行 docker load 将文件导入为镜像 docker load -i jenkins.tar（文件名） 6、创建 Jenkins 工作目录并赋予权限 mkdir -p /home/jenkins/data/jenkins_home/ #设置目录权限 chmod -R 777 /home/jenkins/ #给docker.sock授予权限 chmod 777 /var/run/docker.sock 7、执行命令启动 Jenkins docker run -d --privileged=true \\ --name jenkins-hercules -p 8010:8080 -p 50000:50000 \\ --restart=always \\ -v /home/jenkins/data/jenkins_home:/var/jenkins_home \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /usr/bin/docker:/usr/bin/docker \\ -v /etc/localtime:/etc/localtime \\ --user root \\ jenkins-image 8、参照上方快速迁移方法的4、5、6步将原来的工作目录替换掉现在的即可。 PS: 1、本来我认为保存了整个容器应该将原有的配置内容也都保存了，但启动后我访问 Jenkins 还是让我执行初始化的那些步骤，原来的配置都没了，暂时还没研究是什么原因导致，所以建议直接用快速迁移方法即可。\n2、如果你的 Jenkins 跑了很多流水线的话，实际上你要按照第二种方式备份你的镜像文件是巨大的，我这个将近 15GB 。通过删掉一些不必要的东西如：代码编译后的 Jar、缓存文件夹、maven仓库、npm软件包(前两个在工作目录下，后两个在容器的 root目录下，为隐藏文件夹，可通过 du -sh .[!.]* 显示隐藏目录)。清理后打包容器为镜像后还有 3.4G，如果服务器不是内网有带宽限制会导致文件传输巨慢，浪费时间。\n","permalink":"https://jiangjun8888.github.io/posts/tech/%E8%BF%81%E7%A7%BB%E5%A4%87%E4%BB%BDdocker%E4%B8%ADjenkins%E9%95%9C%E5%83%8F%E6%96%B9%E6%A1%88/","summary":"一、快速迁移方法 1、将 Jenkins 工作目录打包压缩。（因为 Jenkins 的所有配置都存放在工作目录下，所以我们迁移工作目录下的内容即可） 1.1、进入容器挂载的 Jenkins 工","title":"迁移备份Docker中Jenkins镜像方案"},{"content":"一、ES 是什么？ Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsearch 会集中存储您的数据，让您飞快完成搜索，微调相关性，进行强大的分析，并轻松缩放规模。\n​\t上述描述摘自官网，当你能看到我这篇文章的时候，脑海里应该对 ES 有一个初步的概念了，可以把它理解为把数据存放在内存中的 MySQL，它最主要的功能是海量数据实时检索，比起传统的关系型数据库的优点是，没有磁盘 IO 开销，因为索引数据大部分都是存在于内存中的，我们可以通过 ES 提供的 Rest API 像通过 SQL 语句查询关系型数据库中的数据一样，官方的描述是这种查询语言称为 DSL。\nElasticsearch 提供了一个完整的基于 JSON 的查询 DSL（领域特定语言）来定义查询。将查询 DSL 视为查询的 AST（抽象语法树），由两种类型的子句组成：\n叶查询子句 \u0026gt; \u0026gt; 叶查询子句在特定字段中查找特定值，例如 match,term或 range查询。这些查询可以自己使用。\n复合查询子句 \u0026gt; \u0026gt; 复合查询子句包装其他叶查询或复合查询，用于以逻辑方式组合多个查询（例如 boolordis_max查询），或改变它们的行为（例如 constant_scorequery）。\nDSL 使用文档 \u0026gt; \u0026gt; https://www.elastic.co/guide/en/elasticsearch/reference/7.17/query-dsl.html\n二、Kibana 是什么？ Kibana 使您能够塑造数据并在 Elastic Stack 中导航。使用 Kibana，您可以：\n搜索、观察和保护您的数据。 从发现文档到分析日志再到查找安全漏洞，Kibana 是您访问这些功能及更多功能的门户。 分析您的数据。 搜索隐藏的见解，可视化您在图表、仪表、地图、图形等中发现的内容，并将它们组合到仪表板中。 管理、监控和保护 Elastic Stack。 管理您的数据，监控 Elastic Stack 集群的健康状况，并控制哪些用户可以访问哪些功能。 Kibana 文档：https://www.elastic.co/guide/en/kibana/current/introduction.html ​\t可以将 Kibana 理解为方便我们发送 Rest API 请求的一个客户端，相当于专门为 ES 服务器打造的一个 Postman 。\n三、安装ES 、 Kibana ​\t安装前默认你的 Linux 已经具备了 docker、 docker-compose 环境，将下面的配置文件保存为名称是：docker-compose.yml 的文件。\nversion: \u0026#39;3.5\u0026#39; services: elasticsearch: container_name: elasticsearch build: context: services/elasticsearch args: - ES_VER=7.5.0 ports: - \u0026#34;9200:9200\u0026#34; - \u0026#34;9300:9300\u0026#34; environment: ES_JAVA_OPTS: \u0026#34;-Xms512m -Xmx512m\u0026#34; #设置使用jvm内存大小 discovery.type: single-node #以单一节点模式启动 # ELASTIC_PASSWORD: 123456 #设置ES密码 privileged: true volumes: - ./data/elasticsearch/plugins/:/usr/share/elasticsearch/plugins/ - ./data/elasticsearch/:/usr/share/elasticsearch/data/ - ./logs/elasticsearch/:/usr/share/elasticsearch/logs/ - ./services/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml kibana: container_name: kibana build: context: services/kibana args: - KIBANA_VER=7.5.0 ports: - \u0026#34;5601:5601\u0026#34; privileged: true volumes: - ./services/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml depends_on: - elasticsearch ​\t创建好文件后，在文件所属的目录下执行命令： docker-compose -f docker-compose.yml up -d （-d : 在后台所有启动服务, -f : 指定使用的Compose模板文件，默认为docker-compose.yml，可以多次指定。）我这里是安装的 7.5.0 的 ES 版本，Kibana 的版本与之对应，假设设置了 ES 密码，那么后续请求 ES 服务都需要带上身份验证信息，Kibana 也需要输入账户名、密码登录， 账户名默认为：elastic ，密码：yml 文件中设置的 ES 密码。\n四、向 ES 导入 Demo 数据 ​\t访问部署 Kibana 的机器, ip:5601，进入 Kibana 首页，点击网页做下架的展开菜单栏图标，选择 Dev Tools 选项，打开后，在网页左侧可以编写 DSL 语句，向 ES 发送请求，右侧显示相应结果。执行的命令如下,将内容粘贴至 Kibana中，将光标放置在 ：POST bank/_bulk 这一行，行尾右侧边栏回显示一个三角形和一个扳手图标，点击三角形发送请求保存数据。\nPOST bank/_bulk # 粘贴这个网页中的文档数据在下方然后点击执行（感谢此作者）：https://gitee.com/xlh_blog/common_content/blob/master/es%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE.json# 五、ES 入门测试 将以下文档创建名为：ES 7.5.postman_collection.json 的 JSON 文件，然后点击 Postman 左上角的 Import 按钮选中文件导入即可。\n{ \u0026#34;info\u0026#34;: { \u0026#34;_postman_id\u0026#34;: \u0026#34;34d02b44-25de-46e9-b4d2-c03f9e223ffd\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;ES 7.5\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;https://schema.getpostman.com/json/collection/v2.1.0/collection.json\u0026#34;, \u0026#34;_exporter_id\u0026#34;: \u0026#34;11045914\u0026#34; }, \u0026#34;item\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;查看版本\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34; } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;查看节点信息\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/_cat/nodes\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;_cat\u0026#34;, \u0026#34;nodes\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;查看主节点信息\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/_cat/master\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;_cat\u0026#34;, \u0026#34;master\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;查看所有索引\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/_cat/indices\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;_cat\u0026#34;, \u0026#34;indices\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;PUT指定ID保存\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;PUT\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;body\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;raw\u0026#34;, \u0026#34;raw\u0026#34;: \u0026#34;{\\n \\\u0026#34;name\\\u0026#34; : \\\u0026#34;jack\\\u0026#34;\\n}\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;raw\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;json\u0026#34; } } }, \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/1\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;1\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;POST保存\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;body\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;raw\u0026#34;, \u0026#34;raw\u0026#34;: \u0026#34;{\\n \\\u0026#34;name\\\u0026#34; : \\\u0026#34;jack1\\\u0026#34;\\n}\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;raw\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;json\u0026#34; } } }, \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/q1eYgIUBGSRCIL0j0d7A\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;q1eYgIUBGSRCIL0j0d7A\u0026#34; ] }, \u0026#34;description\u0026#34;: \u0026#34;可自动生成ID/指定ID相当于修改，PUT必须指定ID\u0026#34; }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;根据ID查询数据\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/1\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;1\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;删除指定ID数据\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;DELETE\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/1\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;1\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;删除索引\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;DELETE\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] } ] } 六、ES 基础请求 DSL 以下执行语句请在 Kibana 的 Dev Tools 中执行\n## 查询所有 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;sort\u0026#34;: [ { \u0026#34;account_number\u0026#34;: \u0026#34;desc\u0026#34; }, { \u0026#34;balance\u0026#34;: \u0026#34;asc\u0026#34; } ], \u0026#34;from\u0026#34;: 0, \u0026#34;size\u0026#34;: 20, \u0026#34;_source\u0026#34;: [\u0026#34;balance\u0026#34;,\u0026#34;firstname\u0026#34;] } ## 全文检索:会将查询条件分词，任意一个匹配都算匹配 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mail one\u0026#34; } } } ## 短语匹配：不会将查询条件分词，作为一个完整的词去搜索 ## 也可以使用字段.keyword 精确匹配，必须是值和搜索值完全相等 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_phrase\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mail one\u0026#34; } } } ## 多字段匹配,多个字段任意匹配,会分词查询 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;mill one\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;address\u0026#34;,\u0026#34;firstname\u0026#34;] } } } ## bool 复合查询，条件都要满足 and ## must:数组中的条件都要满足 must_not:都不满足 should == or 不是必须满足 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mill\u0026#34; } }, { \u0026#34;match_phrase\u0026#34;: { \u0026#34;firstname\u0026#34;: \u0026#34;mill\u0026#34; } } ], \u0026#34;must_not\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;abc\u0026#34; } } ], \u0026#34;should\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;FIELD\u0026#34;: \u0026#34;TEXT\u0026#34; } } ] } } } ## filter:筛选结果，不计算相关性得分 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;gte\u0026#34;: 10, \u0026#34;lte\u0026#34;: 20 } } } } } } ## 非文本字段检索推荐term GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;value\u0026#34;: 28 } } } } ## 搜索address中包含mi1l的所有人的年龄分布以及平均年龄 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mill\u0026#34; } }, \u0026#34;aggs\u0026#34;: { \u0026#34;ageAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34;, \u0026#34;size\u0026#34;: 10 } }, \u0026#34;ageAvg\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34; } } } } ## 按照年龄聚合，并且请求这些年龄段的这些人的平均薪资 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;aggs\u0026#34;: { \u0026#34;ageAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34; }, \u0026#34;aggs\u0026#34;: { \u0026#34;balanceAvg\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;balance\u0026#34; } } } } }, \u0026#34;size\u0026#34;: 0 } ## 查出所有年龄分布，并且这些年龄段中M的平均薪资和F的平均薪资以及这个年龄段的总体平均薪资 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;aggs\u0026#34;: { \u0026#34;ageAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34; }, \u0026#34;aggs\u0026#34;: { \u0026#34;balanceAvg\u0026#34; :{ \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;balance\u0026#34; } }, \u0026#34;genderAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;gender.keyword\u0026#34;, \u0026#34;size\u0026#34;: 10 }, \u0026#34;aggs\u0026#34;: { \u0026#34;genderBalanceAvg\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;balance\u0026#34; } } } } } } }, \u0026#34;size\u0026#34;: 0 } ## 新建索引时指定字段类型 PUT /my-index { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;email\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; } } } } ## 新建索引后添加字段映射，index:false 不参与搜索 PUT /my-index/_mapping { \u0026#34;properties\u0026#34; : { \u0026#34;id\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34;, \u0026#34;index\u0026#34; : false } } } ## 查看索引字段类型 GET my-index/_mapping ## es指定好映射规则后不允许修改，想要修改只能创建一个新的索引，然后把原有的数据迁移到新索引 GET bank/_mapping ## 创建新索引 指定映射关系 PUT /bank1/ { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34; : { \u0026#34;account_number\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34; }, \u0026#34;address\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34; }, \u0026#34;age\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34; }, \u0026#34;balance\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34; }, \u0026#34;city\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34; }, \u0026#34;email\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;employer\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;firstname\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;gender\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;lastname\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;state\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } } } } } ## 迁移数据到新索引中 POST _reindex { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;bank\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;account\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;bank1\u0026#34; } } GET /bank1/_search { \u0026#34;query\u0026#34; : { \u0026#34;match_all\u0026#34; :{} } } ## 使用默认分词器进行分词 （仅支持英文） POST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;加油努力.\u0026#34; } ## 使用IK分词器分词 ik_smart: 会做最粗粒度的拆分，适合 Phrase 查询。 POST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;加油努力.\u0026#34; } ## ik_max_word: 会将文本做最细粒度的拆分，会穷尽各种可能的组合，适合 Term Query； POST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;加油努力.\u0026#34; } ## 发起批量保存请求 POST my-index/_bulk {\u0026#34;index\u0026#34;:{\u0026#34;_id\u0026#34;:\u0026#34;1\u0026#34;}} {\u0026#34;age\u0026#34; : 1, \u0026#34;email\u0026#34; : \u0026#34;12345@qq.com\u0026#34;, \u0026#34;id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;张三\u0026#34;} {\u0026#34;index\u0026#34;:{\u0026#34;_id\u0026#34;:\u0026#34;2\u0026#34;}} {\u0026#34;age\u0026#34; : 21, \u0026#34;email\u0026#34; : \u0026#34;12345@qq.com\u0026#34;, \u0026#34;id\u0026#34; : \u0026#34;2\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;李四\u0026#34;} 七、相关文档链接 elasticsearch-analysis-ik ：IK分词器，安装了这个才支持对中文进行分词，下载与 ES 对应版本的 Releases 包，解压后放置在 ES 的 plugins 目录下重启 ES 即可。\nelasticsearch-head ：Elasticsearch 集群的可视化 Web 前端，相当于 Navicat 操作 MySQL。\nES 官方文档 ：英文好的同学可以直接翻阅官方文档学习 ES。\n","permalink":"https://jiangjun8888.github.io/posts/tech/elasticsearch%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","summary":"一、ES 是什么？ Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsear","title":"ElasticSearch基础入门教程"}]