[{"content":" 我司的 Java 编写的微服务通过 Docker 容器部署，最近有一项功能需要执行 Python 脚本获取返回值，此时就需要容器中带上Python的环境才可以，记录下搭建过程。\n1、下载带有 JDK11 的基础镜像并进入容器 docker run -it --name base-image adoptopenjdk/openjdk11:centos-jre 2、更新容器中已安装的软件包到最新版本 yum update -y 3、使用 yum 安装一些基础软件包,安装 Python 时需要 yum install wget gcc openssl-devel bzip2-devel libffi-devel -y ● gcc 是 C 编译器，用于编译 Python 的源代码。\n● wget 用于之后从官网下载 Python 安装包。\n● openssl-devel 是 OpenSSL 库的开发包，用于支持加密功能。\n● bzip2-devel 是 bzip2 压缩库的开发包，用于支持 bzip2 压缩算法。\n● libffi-devel 是 libffi 库的开发包，用于支持 C 语言调用外部函数的功能。\n● zlib-devel 是 zlib 压缩库的开发包，用于支持 zlib 压缩算法。\n4、安装 Python3.8.17 1.下载 Python 安装包 wget https://www.python.org/ftp/python/3.8.17/Python-3.8.17.tgz 2.解压安装包至当前目录 tar -xf Python-3.8.17.tgz 3.进入解压后的安装目录 cd Python-3.8.17 4.使用 --enable-optimizations 标志启用一些优化选项 ./configure --enable-optimizations 5.编译 Python。-j 选项可指定编译时使用的核心数，用于加快编译速度。 make -j 4 6.将编译后的 Python 安装到系统中,使用 altinstall 而不是 install 是为了避免覆盖系统默认的 Python 版本。 make altinstall 7.查看 Python 是否安装成功 python3.8 --version 5、设置 pip 镜像源为阿里云，用于后续加速下载python所需的依赖 pip3.8 config set global.index-url https://mirrors.aliyun.com/pypi/simple 6、升级 pip 到最新版本。 /usr/local/bin/python3.8 -m pip install --upgrade pip 7、将后续需要在容器中执行的脚本和依赖文件导入到容器中并安装依赖 pip3.8 install -r requirements.txt 8、exit 命令退出容器，使用 docker commit 命令打包容器为镜像 docker commit -m=\u0026#34;带有java\\python环境的镜像\u0026#34; 第一步时创建的容器ID 镜像名称:镜像版本 9、如果有自己的镜像仓库，可以把打包好的镜像推送到自己的仓库中 1.登录镜像仓库 docker login 镜像仓库地址 -u 用户名 -p 密码 2.推送至镜像仓库 docker push 镜像名称:镜像版本 3.下次需要使用时可以通过 docker pull 命令拉取. ","permalink":"https://jiangjun8888.github.io/posts/tech/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6%E6%9C%89jdk+python%E7%8E%AF%E5%A2%83%E7%9A%84%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F/","summary":"我司的 Java 编写的微服务通过 Docker 容器部署，最近有一项功能需要执行 Python 脚本获取返回值，此时就需要容器中带上Python的环境才可以，记录下搭建过程。 1","title":"构建一个带有Jdk+Python环境的基础镜像"},{"content":"1、受众面 在绝大部分行业和领域，初学者是要比经验成熟的人要多的，到了自媒体平台也是遵循这个规律，一个知识点假如需要深入思考或者晦涩难懂的话，通过信息流软件来学习的人，不一定有这个耐心，就拿一般的技术科普文来说，动不动上万字是家常便饭，大部分人别说看懂了，可能连读完都费劲。\n所以在这种注意力稀缺的今天，越来越多的自媒体，都偏向于制作短平快的内容，没有上下文，切入点也必须降的足够低，需要达到大部分人的都能理解的起点，看似通俗易懂，但也是浅尝辄止，不可避免的趋向浅薄，看完后可能会觉得自己什么都懂一些，但想对这个知识点输出一些自己的见解却做不到，因为输出实际上是要深度思考并归纳总结的，而这类短文短视频并不能产生思考，这也是为了增加受众面不得不做出的妥协。\n现在大部分初学者，或者说大部分人，都被短视频产生的这种实时反馈给裹挟了，消解了我们的注意力，通过短视频、文章、博客这些渠道顶多是了解专业知识的一种方式，无法作为学习知识的主要方式，因为完整的知识都是要成体系的，就好比 Java 中 GC 如何识别需要回收的垃圾？答案是通过可达性分析。假设这个知识在你脑海里是没有串联起来的，那它就不可达，很快就会遗忘掉。\n2、无法共情 头部大厂的员工遇到的问题和普通公司遇到的问题不可同日而语，一些初学者需要的并不是进阶的知识而是一些基础性的理论和求职帮助，这些对于高级程序员或者说架构师眼里都是一些很简单的事，所以在这个初学者占多数的自媒体平台上，注定能吸引到的粉丝是少数。\n3、程序员相对理性 人们趋向于选择和自己同频或者相似的人，大部分程序员都是偏于理性的，所以你想在这群聪明人身上割韭菜或者说没有一点真本事是很难变现的，但初学者刚入门，可能对自己的学习路线不确定，学到的知识因为没有足够的经验去实践，本能的对未知恐惧，就会被一些所谓散播焦虑的自媒体博主给吸引。\n4、缺少破斧成舟的决心 因为大部分资质背景很好的up主，本身自己有一份很好的工作，自媒体对于他们来说只是一个副业，能做好当然好，做不好他们也不会损失什么，并且还要顾及到公司的一些限制，所以很难施展身手，而全职做这类内容的up主没有这些顾虑。\n","permalink":"https://jiangjun8888.github.io/posts/idea/%E8%87%AA%E5%AA%92%E4%BD%93/","summary":"1、受众面 在绝大部分行业和领域，初学者是要比经验成熟的人要多的，到了自媒体平台也是遵循这个规律，一个知识点假如需要深入思考或者晦涩难懂的话，","title":"为什么自媒体上技术up主学历低技术一般的反而流量越大"},{"content":"现在每天巨量的信息冲刷着我们的大脑，抖音，小红书，今日头条这些信息流软件，还有微信公众号，碎片化知识阅读后有很强的头部效应，大脑记住了前几分钟看的内容，又被新的一轮推送给覆盖掉，如果说只是单纯的娱乐性知识不要紧，但有的内容能引发自己的思考，给自己知识体系的查漏补缺，像这类的知识，应该要写下自己的思考和总结，俗话说：学而不思则罔，思而不学则殆。囫囵吞枣的过一遍，大脑没有产生复盘的摩擦力，就会快速遗忘，而思考总结就是给记忆增加摩擦力。以上只是拿信息流软件举例子，实际上看书，学习，或者做事任何你觉得需要记忆的内容都可以采取这方法，虽然说感官上觉得学习效率降低了，因为你要花时间思考，组织语言，文字记录，但学习的内容这一轮复盘中重复了三遍，有效减少了知识的失效率。\n","permalink":"https://jiangjun8888.github.io/posts/idea/%E5%A2%9E%E5%8A%A0%E8%BE%93%E5%85%A5%E7%9A%84%E6%91%A9%E6%93%A6%E5%8A%9B/","summary":"现在每天巨量的信息冲刷着我们的大脑，抖音，小红书，今日头条这些信息流软件，还有微信公众号，碎片化知识阅读后有很强的头部效应，大脑记住了前几分","title":"增加输入的摩擦力"},{"content":"1、Jmeter 是什么？ Jmeter 是一个开源的测试工具，由 Apache 软件基金会开发，它是一个纯 Java 应用程序，用于负载测试、功能测试和性能测试，它是由 Apache 软件基金会开发的一个开源软件。它可以模拟许多不同类型的负载，并且可以用于测试不同类型的应用程序，包括 Web 应用程序、数据库服务器、FTP 服务器、邮件服务器等。JMeter 可以帮助测试人员和开发人员在测试过程中识别应用程序的瓶颈和性能问题，以及分析应用程序的性能。\n2、如何下载？ 点击下载 Jmeter 5.5 版本，也可以自行访问官网下载页选择合适的 Jmeter 版本：https://jmeter.apache.org/download_jmeter.cgi\n3、Jmeter 语言切换为中文简体 3.1、下载完成后解压压缩包 在 bin 目录下双击 jmeter.sh 可执行文件，Windows 系统的同学双击 jmeter.bat 文件启动。\n3.2、切换语言 在菜单栏 Options 中选择 Choose Language 然后选中 Chinese (Simplified) 即可完成切换。\n4、测试 HTTP 请求 4.1、添加线程组 线程组相当于一组测试请求的集合，当启动时，可以将组下面定义的所有请求并行进行测试。\n4.2、配置线程组 实际上就是配置测试的请求次数，像如下的设置代表 10 秒内将会准备 100 个线程发起请求，只循环 1 次，如果循环次数勾选了永远，将会已 100 个请求 /10 秒一直循环下去。\n4.3、添加 HTTP 请求取样器 4.4、GET 请求配置 4.5、POST 请求配置 同样也是先添加 HTTP 请求取样器再设置请求接口和请求参数。\n4.6、添加监听器 监听器的作用就是获取测试结果，可以添加不同类型的监听器从多个维度分析请求结果。\n4.6.1 添加查看结果树监听器 作用是可以单独查看每次请求的测试结果\n4.6.2 添加聚合报告监听器 4.7、开始测试 点击启动后会弹出一个是否需要保存这个测试计划，点击 Yes 的话需要指定保存的磁盘位置，下次测试可以直接读取保存的文件家在测试计划，如果不需要保存点击 No 即可。\n4.8、查看测试结果 可以看到我启动时线程组定义的是 10 个线程数，执行 1 秒。所以两个请求取样器每个发起 10 个请求，一共是 20 个请求结果。\n查看结果树的报告中可以单独点击某一个请求查看请求结果，是根据发起请求的时间来升序排列的，点击单个请求后在右侧可以查看取样器结果、请求内容、响应内容。\n为什么 Post 请求全部失败了呢？因为只要响应状态码不是 2xx 代表操作被成功接收，Jmeter 则认为此次请求是失败的。我们可以看一下响应内容报的是什么原因。\n可以看到响应体提示不支持的 Media Type (媒体类型 用于声明随之而来的数据的格式。又称：MIME 类型、MIME Type、Content Type。 是一种用于在异构系统、网络之间传递信息时时声明其格式的方法。)，所以有开发经验的同学会注意到，我们的请求体内容没有设置 content-type，默认是 application/x-www-form-urlencoded ，这是浏览器原生的 form 表单类型，或者说是表单默认的类型。我们的请求体是 JSON 字符串格式，需要设置一下 content-type 为 application/json。而设置 content-type 是一个属性，而且我们要指定的请求内容的类型，所以需要添加一个 HTTP 信息头管理器。\n添加后就可以将 content-type 设置好，顺便说一句，如果接口设置了身份校验，需要请求头中携带 token 信息，也可以在这一并设置。\n添加后，启动测试，发现接口响应成功。\n查看聚合报告，聚合报告中对测试的请求进行了区分统计，可以查看到平均的响应时间 (单位均为毫秒)、TP99 的时间，请求异常比例，吞吐量等。\nLabel：请求的名称，就是我们在进行测试的 TCP sampler 的名称 Samples：总共发给服务器的请求数量 Average：单个请求的平均响应时间，单位是毫秒 Median：50% 的请求的响应时间 90%Line：90% 的请求的响应时间 95%Line：95% 的请求的响应时间 99%Line：99% 的请求的响应时间 Min：最小的响应时间 Max：最大的响应时间 Error%：错误率 = 错误的请求的数量 / 请求的总数 Throughput：吞吐量即表示每秒完成的请求数 Received KB/sec：每秒从服务器端接收到的数据量 Sent KB/Sec：每秒从发送到服务器端的数据量 5、测试 TCP 请求 5.1、添加 TCP 请求取样器 5.2、TCP 取样器配置说明 TCPClient classname：\nTCPClientImpl：以文本编辑器中所编辑的纯文本为内容进行发送，默认为这种 BinaryTCPClientImpl：以文本编辑器中所编辑的 16 进制字符（hex）内容为基础转换为二进制的 字节内容进行发送。 LengthPrefixedBinaryTCPClientImpl：在 BinaryTCPClientImpl 基础上默认以发送内容的长度为字节前缀进行填充, 数据包中前 2 个字节为数据长度。可在 bin/jmeter.properties 配置文件中 tcp.binarylength.prefix.length 设置。 Target Server：TCP 采样器中填写服务器地址、端口。\nConnect：设置连接超时时间。\nResponse： 设置响应超时时间。\nRe-use connection： 表示重复使用该连接发送请求。\nClose connection： 表示每次发送完该条数据后，关闭连接。\nEnd of line(EOL) byte value： 终止符。\n比如项目中返回值转为 16 进制的时候如下： 7e800100050100019040011000000003010201447e 那么最后一个字节（8 位）应该是 7e 换算为 10 进制后为 126，那么在 eol 处设置为 126。\n注意：终止符为一个字节，16 进制数大于 7F(127) 后，该 EOL 值为负数。\n比如：如果服务器返回最后一个字节为 80，按单字节换成十进制为 -128，EOL 处的值要填写 -128。\n如果响应内容不是 16 进制内容，是普通文本的话，就是最后一个字节对应的 ASCII 码。\n5.3、开始测试并查看结果 可以看到响应状态码都是 500，代表响应发生错误，并且异常消息为：Response message:org.apache.jmeter.protocol.tcp.sampler.ReadException: Error reading from server, bytes read: 32，\n但是查看响应数据发现实际上是响应成功了的，返回了正确的响应数据结果，其实原因是这个异常是 jmeter 自身抛出来的，我们都知道 TCP 请求不像 HTTP 定义了 1xx、2xx 这类的响应状态码，那是什么原因导致出现了异常呢？\n答案是我们没有配置 End of line(EOL) byte value： 终止符，导致 jmeter 认为响应内容不完整从而抛出 ReadException。 我们的响应数据最后一位字节是 1 ，对应的 ASCII 码 是 49。所以我们去设置一下再启动测试。\n最终测试结果：\n","permalink":"https://jiangjun8888.github.io/posts/tech/%E4%BD%BF%E7%94%A8jmeter%E5%8E%8B%E6%B5%8Bhttptcp%E8%AF%B7%E6%B1%82/","summary":"1、Jmeter 是什么？ Jmeter 是一个开源的测试工具，由 Apache 软件基金会开发，它是一个纯 Java 应用程序，用于负载测试、功能测试和性能测试，它是由 Apache 软件基金","title":"使用Jmeter压测HTTP、TCP请求"},{"content":"《刻意练习：如何从新手到大师》 安德斯·艾利克森 罗伯特·普尔\n◆ 相信天生才华的危险性\n这就是相信天生才华的危险性。它往往使人们假设，有些人生来就具有某些方面的天赋，而另一些人则不具备，而你可以很早就分辨他们之间的这些差别。如果你相信这种观点，那么，你就是在鼓励和支持“有天赋”的那些人，并打击其他的人，从而制造自我实现的预言。\n人类的天性是希望在他们做得最好的方面投入自己的努力，包括时间、金钱、教育、鼓励、支持等，并且试图保护自己的孩子不至于失望。这种想法和做法并没有恶意，但其结果却具有惊人的破坏力。避免这种现象，最好的办法是意识到我们每个人都有自己的潜力，并努力想办法去开发这些潜力\n◆ 刻意练习的前景\n韦曼和他的同事为了帮助班上的物理学生创建那样的心理表征，提出了一些课堂问题，并布置了学习任务，有助于学生达到老师此前确定的学习目标。那些课堂问题和学习任务经过精挑细选，目的是引起学生的讨论，进而掌握和应用他们正在学习的概念，最后运用那些概念来回答课堂问题和完成学习任务。\n他们给这些学生提出问题、交代任务，然后让他们在推理答案的时候自言自语，把自己的推理过程说出来。他们根据这个环节中学生所说的东西，再去修订那些问题和任务，特别强调要避免错误理解以及对学生来说太难的问题。然后，他们再在另一组志愿者身上进行第二轮测试，再次调整问题与任务。\n◆ 创造全新的世界\n在各行各业中最杰出的人物之所以占据那些地位，并不是因为他们天生具有某种才能，而是因为他们通过年复一年的练习，充分利用人类的身体与大脑的适应能力而提升和发展了自己能力，那么，这种颠覆就开始了\n此外，我还坚持认为，当我们在提高自己时，我们才最像是人类。和其他任何动物不同，我们可以有意识地改造自己，以我们选择的方式来提高自己。这使得我们和当今世界以及有史以来的其他物种区别开来。\n我们可以给孩子们留下的最重要礼物，是对他们能力的巨大信心，相信他们能够一次又一次地重新塑造自己，同时还创造一些工具来提升自己。他们需要通过发展和提高自己认为不可能具备的能力，亲眼见证自己能够掌控自己的潜能，而且不会沦为某种熟悉的天才论的人质。他们需要获得支持和理解，以便以他们选择的各种方式来提高自己。\n","permalink":"https://jiangjun8888.github.io/posts/read/%E5%88%BB%E6%84%8F%E7%BB%83%E4%B9%A0%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","summary":"《刻意练习：如何从新手到大师》 安德斯·艾利克森 罗伯特·普尔 ◆ 相信天生才华的危险性 这就是相信天生才华的危险性。它往往使人们假设，有些人生来就具","title":"《刻意练习》阅读笔记"},{"content":"举一个很简单的例子，当我说“不要去想一头蓝色的大象！不要去想一头蓝色的大象！”时，你此刻 的脑袋里是不是偏偏塞满了蓝色的大象呢？\n情绪也一样。我们对自己说：“不要焦虑！不要焦虑！”却只会越来越焦虑。\n分散注意力、让杏仁核冷却的事情： 例如：点外卖、玩电脑游戏、出门跑步、跳舞、K歌……\n除此之外，深呼吸也可以让人平静。 如果你已经在情绪爆炸的边缘，那么可以用“4-4-4-4”的“方块呼吸法”来三次呼吸循环，阻止情 绪炸弹瞬间引爆。 “方块呼吸法”是指，吸气时心中默数4下，再屏住呼吸默数4下，吐气默数4下，最后再屏住呼吸默 数4下。如此循环三次。\n实际上，我们很多时候并不是真的遇到了特别糟糕的事情，而是对普通的事情进行了非常糟糕的解 读，才产生了不良情绪。 而且，越是在抑郁、焦虑等消极的情绪状态下，我们越容易对事情进行消极解读，并且相信自己的解 读。\n在这个时候，重要的不是追根溯源，弄清我们为什么要这样理解，而是要很清楚地知道，我们对一件 事情的理解并不见得是真实的，可能只是我们自己的想法而已。它不一定是真实发生的事实，或许只是一 个心理事件。\n你有价值 值得被爱 可以犯错\n若想要训练我们的情绪，最重要的就是能够辨别上述错误信念，意识到那些影响我们的往往并不是真 实发生的事情。\n正念冥想\n开始正念冥想最简单的方式就是“数自己的呼吸”。 不需要借助任何技巧和引导，只需要像睡前数绵羊一样默默数着自己的呼吸。 呼气——1，吸气——2，呼气——3，吸气——4……以此类推。 不需要控制呼吸，次数也不用很多，如果能数到100，你就已经完成了一次简单且有效的正念训练。\n将正念冥想融入心理治疗的正念认知疗法（MBCT）被认为是对缓解抑郁状态非常有效的情绪治疗训练 方法。 它的原理是：通过正念来提升训练者的觉察能力，使其能够及时觉察自己的感受和想法；之后针对自 己的感受和想法，使用之前我们介绍过的情绪应对方法，重新理解自己的感受。通过正念冥想和针对情绪 的认知技巧，正念认知疗法试图培养一种温和而不带评判色彩的对自己的理解和接纳。 希望系统了解正念认知疗法并自我训练的读者，推荐你阅读《八周正念之旅——摆脱抑郁与情绪压 力》 。\n如果有太多激烈的情绪出现，需要发泄，一个很好的疏解方式就是写日记。\n当你产生失控情绪之后，可以按照下面的模板来记录当时的情绪变化，以这种方式来缓解杏仁核的充血。\n日期：\n发生了什么事情：\n我的感受是什么：\n产生了什么情绪：\n该用怎样的方式疏解：\n很重要的一件事就是，千万不要被“追求开心”的目标绑架，被“没有成功获得开心”的沮丧包围。不要被“迫切想要获得好心情”的念头影响了心情。\n要看到自己正在一点一滴地变好，也要清楚自己并不可能一下子成为一个情绪高涨的人。要允许自己不完美，允许一切状态上的“不好”存在。我们要训练的是对所有状态（无论好坏）的觉察能力，正视它们的存在，更好地在生活中应对它们。不要被它们控制，也不要试图控制它们。这很重要。\n了解你的优势非常重要，这就等于找到了你的武器；看到你的弱点也很重要，你可以更清楚地知道该如何自我调适、做出必要的防御。当我们把力量集中用到优势部分，可以更快速地看到成效；至于劣势的部分，则可以降低预期，更好地自我接纳并减轻挫败感。\n实际上，每个人都是某个领域的专家。你可能对星座很有研究，可能在做工作简报时比同事的思路更清晰，也许你很擅长调试路由器，或是对你家附近超级好吃的馆子如数家珍。要知道，我们所拥有的“优势”不一定能换来诺贝尔奖，但一定可以在某个微小的层面提升我们和身边人的生活质量。它也许会在不经意间为你赢来一个工作机会或一段美好的关系，也有可能在一些关键时刻决定你的人生选择。同时，每个对你来说微小却有效的优势，只有通过真正的行动上的积累，才有可能发展成拥有重大创造力的日常。\n坦诚：你是个诚实的人,不止说实话,还会以很真实的态度生活和与别人交往。你是个实事求是的人,不会假装自己的情绪和状态,是个「真心」的人。\n奢侈品可以买到，但能 不能换来别人的尊重我们却无法控制；减肥可以成功，但能不能让那些曾说你丑的人称赞你，我们无法控 制；成就可以获得，但能不能因此让讨厌你的人对你刮目相看，我们同样无法控制。别人的感受是我们无 法左右的，以此为目标去追逐，最终只会感到无能为力和失落。\n正确的处理方式是，随意去做一件虽然现在没兴致但曾经令你很开心的事情，比如出门逛街、健身、 看电影、吃顿好饭或者约朋友聊天。即使一开始你因为缺乏活力而不太舒服，但最终你会发现在这一过程 中，疲惫和抑郁逐渐消失了。\n正是因为这些思维的预设，我们才会一圈一圈逐渐沉沦，彻底被情绪的黑洞吞噬。 因此，请忽略一切预设与担忧，直接行动，去做一些不一样的事情。出门走走、做运动、与喜欢的朋 友联络都是迅速建立积极状态的好办法。 在做事的过程中，你的状态就会慢慢发生改变。行动之后记住好的感受，淡忘不适和焦虑，渐渐就不 会对这些行为产生消极的预判了，你也会因此发现更多“可以迅速改变消极状态”的行动。 行动是激发活力、消除疲惫的最好办法。 先动起来再说。\n积极心理学之父、美国心理学会前主席马丁·塞利格曼曾提到过能帮助职场人缓解抑郁的5个积 极心理习惯：\n①写一封邮件，表扬一个你认识的人。 ②写下3件你觉得感激的事。 ③花2分钟记录一段积极的经历。 ④做30分钟的有氧运动。 ⑤冥想2分钟。 哈佛大学的“幸福课”也提供了“幸福鸡尾酒”，它由4种成分组成：\n①每周4次，每次半小时的锻炼。 ②每周六6—7次，每次至少15分钟的意念锻炼（冥想）。 ③每天8个小时的睡眠。 ④每天12个以上的拥抱。（抱人，抱宠物，抱枕头，抱自己 我们可以尝试在日常的社交训练中脱离那些过度的准备，只需让自己外表干净整洁，没有负担地 与人沟通，以最自然的状态去参与活动。你会发现，你在松弛中变得更自然、更真诚了，也因此减轻 了社交的疲惫感。\n我们都认为开心是努力之后的奖励，是付出许多东西之后才换来的。甚至很多人会认为，在成功之前 我们没有资格开心，但在我看来，这些都是我们对开心的误解。 实际上，只有处在积极情绪里的人，才有更好的状态和能量去创造、去前进、去完善。 我们把开心和成功的顺序搞反了，于是“努力”就成了一件特别辛苦的事情。这不仅影响了我们做事 的效率，也直接降低了我们日常生活的质量。 一起看一下“工作不快乐”的死循环是如何形成的吧。（同样的原理也适用于“学习不快乐”。）\n生活实苦，就不要吝惜给自己快乐，就要去随时随地感受细微的美好和小小的进步。在成为“人上人”之前，如果无止境地沉溺于“苦中苦”，可能会被无尽的苦难彻底压倒。 在我看来，李诞那句非常流行的“开心点儿，人间不值得”也有这么一层含义。\n影响效率的是分心和拖延，而导致拖延的一个原因是，我们认为需要去做的事情是痛苦的、有压力的。趋利避害是人的本性，当我们认为一件事情是可怕的、痛苦的，我们自然会选择去做更容易的事。 于是分心、享乐、做更轻松的事情成了我们的第一选择，真正重要的事情则被我们抛在了一旁。长远 来看，因为重要事情的拖延，我们最终只会获得更多的不快乐。 要改善拖延，最重要的一步是，不把要做的事情想得太可怕。\n我们可以通过自主设计，让做事的过程变得快乐起来。快乐不仅是结果，也不仅是前提，它可以持续 存在于整个努力的过程中。游戏之所以好玩，是因为奖励及时，玩家随时拥有愉悦的体验和升级的反馈。 所以游戏的设计非常符合积极心理学中的“心流原理”——将快乐代入努力过程。\n正反馈\n第一，想象成功的状态。 我们可以幻想自己已经非常成功，这样的喜悦可以强化我们做事情的能力和动力，积极的情绪状态也 可以反过来影响我们的自我效能感。当我们提高了效能感，自信心和动力就会增强，甚至连走路也会变 快。 人体是一个复杂的系统，它会习惯性地为外在表现找原因。如果你表现出非常强烈的自我效能感，那么大脑就会自动将之解读为你真的拥有这方面的能力。所以说，如果每天都做出成功的样子，成功可能就 真的会慢慢靠近你。\n因此很多工作都需要前期的培训，技能类职业则需要一段枯燥而长久的“刻意训练”。这种训练的过 程必然是重复的、无趣的，直到你的“业务能力”能够驾驭你的“业务内容”，你才能体验到工作的乐 趣。在心流体验下，所有的职业都类似于一种“演奏”——旁人看我们工作，就像我们欣赏音乐家的表演 一样，从内到外都是愉悦与享受。\n但是，必须先熬过一段不算愉悦的“刻意训练”或“经验积累”。\n这对所有人来说都是一样的。 知道这一点，我们就会对刚开始工作时的积累阶段没有那么多抱怨，也会更积极地投入其中，因为它 对每个人都很公平——没有积累和训练，大家都很难提升应对工作挑战的能力，也就更难获取工作时的愉悦了。\n那些在公司体系里获得稳定提升的人，都是实力和工作内容相匹配的人。否则，即使获得了很好的机 会，没有能力去驾驭，也只会徒增工作的压力和焦虑，导致最终无法把握机会。\n我们先确定那个长远的目标，然后将回报平分到每一月、每一周、每一天，设定一些象征性的节点来 犒劳自己每个时间段的成就，不要等到最后才给自己积极的反馈。\n很多时候我们产生拖延的原因并不是我们不想做好，而是完美主义。我们对接下来要做的事情预期太 高了，这导致我们非常害怕失败，迟迟无法开始。 所以，当我们面临很多重要的考验时，严重的拖延只是为了避免面临失败。 这并不是你一个人的问题，而是一种非常普遍的情况。当然，这也是我们被大脑的“自动导航系统” 控制的表现，我们对一个未知的结果产生了本能的恐惧。\n无论你正面对多么大的挑战，无论你正处在多么糟糕的状态里，无论你身边有多少麻烦的事情 缠绕，无论你有多少借口让自己拒绝行动，你都只需要告诉自己：“嘿，不用太久，先开始做5分钟吧。”除了人命关天的大事，一般的杂事都可以等上5分钟——发微信、回邮件、做家务、打游戏统统可 以5分钟之后再进行\n笑能让你的头脑以最快的速度进入一种好的情绪状态。大脑其实很好骗，即使现实中没有什么开心的 事情，但只需要笑，头脑就会认为我们正处于开心的状态，也会因此分泌一些愉悦的神经递质，逐渐改善 我们的情绪状态。 多笑、动起来，都是让我们情绪变好、状态兴奋的简单方式。\n写下感恩日记或记录一天中的愉悦瞬间。 回忆一天中值得感恩的三件事，或者三个美妙的瞬间，为自己的快乐持续积攒能量。\n我一般会在每次“45分钟专注”的最后5分钟，大概记录一下我在这个时段的工作量。 了解自己每个时段的工作量，了解自己的工作效率，以后做工作规划的时候就不会出现任务过多或过 少的情况了。这样既能对自己的工作进度有一个合理的预估，也会更容易达成目标，减少无法兑现的工作承诺。要知道，无法兑现的承诺既会让你对自己失望，也会损害你在别人心中的信誉，徒增很多愧疚和压力，害人又害己。\n","permalink":"https://jiangjun8888.github.io/posts/read/%E5%A5%BD%E5%BF%83%E6%83%85%E6%89%8B%E5%86%8C%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","summary":"举一个很简单的例子，当我说“不要去想一头蓝色的大象！不要去想一头蓝色的大象！”时，你此刻 的脑袋里是不是偏偏塞满了蓝色的大象呢？ 情绪也一样。我","title":"《好心情手册》阅读笔记"},{"content":"问题背景： 我们现在项目的 Nacos 由于需要适配 Oracle 数据库所以在 Github 仓库中拉取的 Nacos 多数据源分支的源码，此分支的 Nacos 版本为 1.4.1，部署方式是通过 Dockerfile 打包为镜像通过容器运行在服务器上。领导告知我开发服务器上有一天磁盘被占满，通过排查下来发现是 Nacos 容器日志占用了大量的磁盘空间，让我处理一下，就有了今天这篇文章复盘。\n导致原因： 通过 docker exec 命令进入容器后，发现日志文件主要集中在两个目录下，一个是 /logs，一个是 /root/nacos/logs 目录。\n通过查看官方文档中的 FAQ(常见问题解答) 搜索 “日志” 关键词，看到有一个 日志打印频繁的问题 的标题，写道：\n在老的Nacos版本中，往往会有大量的无效日志打印，这些日志的打印会迅速占用完用户的磁盘空间，同时也让有效日志难以查找。目前社区反馈的日志频繁打印主要有以下几种情况：\naccess日志大量打印，相关issue有：https://github.com/alibaba/nacos/issues/1510。主要表现是{nacos.home}/logs/access_log.2019-xx-xx.log类似格式文件名的日志大量打印，而且还不能自动清理和滚动。这个日志是Spring Boot提供的tomcat访问日志打印，Spring Boot在关于该日志的选项中，没有最大保留天数或者日志大小控制的选项。因此这个日志的清理必须由应用新建crontab任务来完成，或者通过以下命令关闭日志的输出（在生产环境我们还是建议开启该日志，以便能够有第一现场的访问记录）： server.tomcat.accesslog.enabled=false 服务端业务日志大量打印且无法动态调整日志级别。这个问题在1.1.3已经得到优化，可以通过API的方式来进行日志级别的调整，调整日志级别的方式如下： # 调整naming模块的naming-raft.log的级别为error: curl -X PUT \u0026#39;$nacos_server:8848/nacos/v1/ns/operator/log?logName=naming-raft\u0026amp;logLevel=error\u0026#39; # 调整config模块的config-dump.log的级别为warn: curl -X PUT \u0026#39;$nacos_server:8848/nacos/v1/cs/ops/log?logName=config-dump\u0026amp;logLevel=warn\u0026#39; 客户端日志大量打印，主要有心跳日志、轮询日志等。这个问题已经在1.1.3解决，请升级到1.1.3版本。 由此可知，/logs 目录下存储的是tomcat访问日志，/root/nacos/logs 目录存储的是 Nacos 自身运行记录的一些日志（心跳、服务轮询、推送等）。\n解决方案： 1、修改 Nacos console 模块的配置文件 /console/src/main/resources/application.properties，将tomcat访问日志关闭。\nserver.tomcat.accesslog.enabled=false 2、通过查阅资料得知，Nacos 自身服务器的日志打印设置在 nacos-distribution 模块下的 distribution/conf/nacos-logback.xml中。\n\u0026lt;!--节选naming-push.log的配置信息--\u0026gt; \u0026lt;appender name=\u0026#34;naming-push\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${LOG_HOME}/naming-push.log\u0026lt;/file\u0026gt; \u0026lt;append\u0026gt;true\u0026lt;/append\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;${LOG_HOME}/naming-push.log.%d{yyyy-MM-dd}.%i\u0026lt;/fileNamePattern\u0026gt; \u0026lt;maxFileSize\u0026gt;1GB\u0026lt;/maxFileSize\u0026gt; \u0026lt;maxHistory\u0026gt;7\u0026lt;/maxHistory\u0026gt; \u0026lt;totalSizeCap\u0026gt;3GB\u0026lt;/totalSizeCap\u0026gt; \u0026lt;cleanHistoryOnStart\u0026gt;true\u0026lt;/cleanHistoryOnStart\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;Pattern\u0026gt;%date %level %msg%n%n\u0026lt;/Pattern\u0026gt; \u0026lt;charset\u0026gt;UTF-8\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt;\tNacos 自身 30+ 个日志的配置都在这个日志配置文件中，可以看到 naming-push.log 日志单个文件最大大小为 1GB，总大小为 3GB ，最多保存 7 日内的日志文件，按最大大小 3GB 来算， 30个日志文件配置每个日志都占用最大的磁盘空间，那就是 3 * 30 = 90GB,何况还有好几个文件最大的日志总大小为 7GB,所以光日志就能占用 100 多GB的磁盘空间。所以我通过我们服务器的磁盘空间和日志的重要程度评估，将所有配置日志文件的占用大小一一修改，使得 Nacos 自身日志总占用空间最多不超过 5G。至此解决了 Nacos 日志占用磁盘空间过大的问题。\n其它: 有的公司 Nacos 是使用 zip 包的方式通过 sh 文件启动，我也下了一个，需要修改的配置文件位置我用图贴出来，按照上方的配置方式修改箭头指向的文件内配置即可。\n还有直接用 Docker 拉取的官方镜像 run 的，也是同样的方式，换汤不换药，进入容器找到这两个配置文件修改。\n网上有很多博客解决 Nacos 日志过大的方式是通过 Linux crond 执行清理脚本的方式，这种方式当然也可以，但如果不需要查看日志文件的话，使用我这种直接关闭 tomcat 访问日志，减小 Nacos 服务器日志最大占用空间的方式更加稳定。\n","permalink":"https://jiangjun8888.github.io/posts/tech/%E8%A7%A3%E5%86%B3nacos%E6%97%A5%E5%BF%97%E5%8D%A0%E7%94%A8%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4%E8%BF%87%E5%A4%A7%E9%97%AE%E9%A2%98/","summary":"问题背景： 我们现在项目的 Nacos 由于需要适配 Oracle 数据库所以在 Github 仓库中拉取的 Nacos 多数据源分支的源码，此分支的 Nacos 版本为 1.4.1，部署方式是通过 Dockerfile 打包为镜","title":"解决Nacos日志占用磁盘空间过大问题"},{"content":"什么是幂等？ 用户对于同一操作发起的一次请求或者多次请求的结果是一致的。\n数据库操作中：SELECT UPDATE DELETE 操作天然就是幂等的，同样的语句执行多次结果都不会产生变化，唯一的就是受影响的行数会变化，但 INSERT 插入操作则不是(在未指定主键或唯一性字段的前提下)；所以需要我们在Java层面保证请求为幂等。否则会出现多次下单、数据异常、扣款重复等情况。闲话少说，说时迟那时快，抄起键盘就是干！\n1、定义一个幂等校验的注解,使用的时候放在需要保证幂等的请求方法上即可。 /** * 标识接口需要保证幂等,未登录接口请勿使用 * @author Jiang Jun */ @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Idempotent { /** * 间隔时间(ms)，小于此时间视为重复提交 */ int interval() default 5000; /** * 提示消息 */ String message() default \u0026#34;不允许重复提交，请稍候再试\u0026#34;; } 2、定义一个拦截器，在 preHandle 方法中做幂等性校验 其中一些我系统本身自定义的类可以替换成你自己工程的类，主要的校验逻辑不受影响，校验是否幂等我采用的判断方式是：使用 Redis 的 String 类型存储请求参数，用户 ID+URI 作为 Key 保证接口请求的唯一性，Value 存储的是本次请求参数的 MD5摘要，MD5担心有的小伙伴不懂我解释一下： MD5 即 Message-Digest Algorithm 5（信息-摘要算法5）常用于文件校验。不管文件多大，经过 MD5 后都能生成唯一的 MD5 值。\n/** * 对方法上标注了幂等请求注解进行幂等校验 * @author Jiang Jun */ @Component public class IdempotentInterceptor implements HandlerInterceptor { @Resource private RedissonClient redissonClient; /** * 防重提交 redis key */ public static final String REPEAT_SUBMIT_KEY = \u0026#34;repeat_submit:\u0026#34;; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (handler instanceof HandlerMethod) { HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); Idempotent annotation = method.getAnnotation(Idempotent.class); if (annotation != null) { // 判断是否为重复提交 if (this.isRepeatSubmit(request, annotation)) { String responseBody = JSON.toJSONString(ResponseResult.error(ErrorCodeEnum.NO_ERROR, annotation.message())); response.setStatus(HttpStatus.OK.value()); response.setContentType(MediaType.APPLICATION_JSON_VALUE); response.setCharacterEncoding(StandardCharsets.UTF_8.name()); response.getWriter().print(responseBody); return false; } } return true; } return true; } /** * 判断是否重复提交 * @param request 请求对象 * @param annotation 幂等注解 * @return 重复提交请求返回true */ private boolean isRepeatSubmit(HttpServletRequest request, Idempotent annotation) throws IOException, NoSuchAlgorithmException { // 用户ID+URI为Redis的Key,请求参数md5摘要为Value String userId = TokenData.takeFromRequest().getUserId(); String uri = request.getRequestURI(); String key = REPEAT_SUBMIT_KEY + userId + uri; RBucket\u0026lt;String\u0026gt; bucket = redissonClient.getBucket(key); // 获取请求体参数 String requestBody = getRequestBody(request); if (StringUtils.isBlank(requestBody)){ requestBody = JSON.toJSONString(request.getParameterMap()); } // redis查询不为null，并且本次的请求参数md5与val相同则为重复请求 if (StringUtils.isNotBlank(bucket.get())){ return bucket.get().equals(jdkMD5(requestBody)); } // 如果redis中没有数据，将本次请求参数存入Redis，考虑到并发情况，trySet 如果已经存在则返回false,代表重复请求 return !bucket.trySet(jdkMD5(requestBody), annotation.interval(), TimeUnit.MILLISECONDS); } /** * 读取请求体内容 */ private String getRequestBody(HttpServletRequest request) throws IOException { return IOUtils.toString(request.getReader()); } /** * MD5摘要并转换为字符串 */ private static String jdkMD5(String str) throws NoSuchAlgorithmException { MessageDigest messageDigest = MessageDigest.getInstance(\u0026#34;MD5\u0026#34;); byte[] mdBytes = messageDigest.digest(str.getBytes()); return DatatypeConverter.printHexBinary(mdBytes); } } 这样校验幂等的工作就完成了，当我感到万事大吉可以潇洒的收起 C V 键帽时。。。又遇到了新的问题：测试的时候 SpringMVC 在解析请求参数转换为我们接收请求参数的实体对象时抛出了一个异常：\njava.lang.IllegalStateException: getReader() has already been called for this request at org.apache.catalina.connector.Request.getInputStream(Request.java:1069) at org.apache.catalina.connector.RequestFacade.getInputStream(RequestFacade.java:365) at com.igg.aggregate.server.aspect.LogAspect.before(LogAspect.java:80)\n原因分析： HttpServletRequest 的 getInputStream() 和 getReader() 都只能读取一次，由于 Request Body 是流的形式读取，那么流读了一次就没有了，所以只能被调用一次。因为我在拦截器中读取了请求体内容，然后 SpringMVC 的参数转换器读取的时候发现已经被读取过了。\n解决办法： 定义一个 RepeatedlyRequestWrapper 类继承 Servlet 自带的 HttpServletRequestWrapper 类，构造方法中先将 Request Body 内容保存在我们重写的 RequestWrapper 的成员属性中，通过覆盖 getReader() 和 getInputStream() 方法，使流从我们自己保存的地方读取。然后使用 Filter 过滤器将原始的 ServletRequest 包装成为 我们自己重写的 RequestWrapper对象。\n3、定义重写后的 RequestWrapper 类 /** * 构建可重复读取inputStream的request * @author Jiang Jun */ public class RepeatedlyRequestWrapper extends HttpServletRequestWrapper { /** * 存放请求体数据 */ private final byte[] body; public RepeatedlyRequestWrapper(HttpServletRequest request, ServletResponse response) throws IOException { super(request); request.setCharacterEncoding(StandardCharsets.UTF_8.name()); response.setCharacterEncoding(StandardCharsets.UTF_8.name()); // 首次读取请求体内容从原生request对象中获取,之后读取都从本对象的重写方法中获取请求体内容 body = IOUtils.toString(request.getReader()).getBytes(StandardCharsets.UTF_8); } @Override public BufferedReader getReader() throws IOException { return new BufferedReader(new InputStreamReader(getInputStream())); } @Override public ServletInputStream getInputStream() throws IOException { final ByteArrayInputStream bais = new ByteArrayInputStream(body); return new ServletInputStream() { @Override public int read() throws IOException { return bais.read(); } @Override public int available() throws IOException { return body.length; } @Override public boolean isFinished() { return false; } @Override public boolean isReady() { return false; } @Override public void setReadListener(ReadListener readListener) { } }; } } 4、定义一个 Filter ，在请求刚进入的时候将 Request 对象转换为我们定义的 RepeatedlyRequestWrapper 至于为什么能转换，看图： /** * 把HttpServletRequest转换为可重复读取的inputStream的request * @author Jiang Jun */ public class RepeatableFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { ServletRequest requestWrapper = null; if (request instanceof HttpServletRequest \u0026amp;\u0026amp; StringUtils.startsWithIgnoreCase(request.getContentType(), MediaType.APPLICATION_JSON_VALUE)) { // 如果是application/json格式的请求体,则将Request转换为可重复读取输入流的形式 requestWrapper = new RepeatedlyRequestWrapper((HttpServletRequest) request, response); } if (null == requestWrapper) { chain.doFilter(request, response); } else { chain.doFilter(requestWrapper, response); } } } 5、将我们的拦截器、过滤器都加入SpringMVC 中使之生效（我使用的 SpringBoot 工程，如您使用的 SSM 请自行百度如何添加） /** * SpringMVC 配置 * @author Jiang Jun */ @Configuration public class WebMvcConfig implements WebMvcConfigurer { @Bean public IdempotentInterceptor idempotentInterceptor(){ return new IdempotentInterceptor(); } @Override public void addInterceptors(InterceptorRegistry registry) { // 添加幂等校验拦截器 registry.addInterceptor(idempotentInterceptor()).addPathPatterns(\u0026#34;/**\u0026#34;); } /** * 此过滤器作用为把HttpServletRequest转换为自定义可重复读取的inputStream的request * 否则在拦截器中读取了请求体中的数据,在参数解析器中无法再次读取 */ @Bean @SuppressWarnings({ \u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34; }) public FilterRegistrationBean someFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new RepeatableFilter()); registration.addUrlPatterns(\u0026#34;/*\u0026#34;); registration.setName(\u0026#34;repeatableFilter\u0026#34;); registration.setOrder(FilterRegistrationBean.LOWEST_PRECEDENCE); return registration; } } 经过以上步骤的准备就可以保证我们的接口是幂等的了，使用方法就是将幂等注解添加到请求方法上即可，开不开心？意不意外？简不简单？（狗头），不足之处是不支持没有任何参数的请求，当然这种请求大多数情况下也不需要保证幂等，另外就是 key 和用户ID绑定了，如果需要解耦可改为在请求幂等接口前后端生成本次请求的唯一请求编号或 Toekn，前端请求的时候带上，实际效果本人已通过 JMerter 并发测试有效。\n","permalink":"https://jiangjun8888.github.io/posts/tech/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E6%80%A7%E6%A0%A1%E9%AA%8C%E6%B3%A8%E8%A7%A3%E5%AE%9E%E7%8E%B0/","summary":"什么是幂等？ 用户对于同一操作发起的一次请求或者多次请求的结果是一致的。 数据库操作中：SELECT UPDATE DELETE 操作天然就是幂等的，同样的语句执行多次结","title":"接口幂等性校验注解实现"},{"content":"CPU 的使用会飙升，一旦飙升，一般怀疑某个业务逻辑的计算量太大，或者是触发了死循环（比如著名的 HashMap 高并发引起的死循环），也有可能是 GC 导致的，如：堆已经满了，但是又没有发生 OOM，于是 GC 进程就一直在那里回收，回收的效果又非常一般，造成 CPU 升高应用假死。\n（1）使用 top 命令，查找到使用 CPU 最多的某个进程，记录它的 pid。使用 Shift + P 快捷键可以按 CPU 的使用率进行排序。\ntop （2）再次使用 top 命令，加 -H 参数，查看某个进程中使用 CPU 最多的某个线程，记录线程的 ID。\ntop -Hp $pid （3）使用 printf 函数，将十进制的 tid 转化成十六进制。\nprintf %x $tid （4）使用 jstack 命令，查看 Java 进程的线程栈。\njstack $pid \u0026gt;$pid.log （5）使用 less 命令查看生成的文件，并查找刚才转化的十六进制 tid，找到发生问题的线程上下文。\nless $pid.log ","permalink":"https://jiangjun8888.github.io/posts/tech/java%E8%BF%9B%E7%A8%8B%E5%AF%BC%E8%87%B4cpu%E8%B4%9F%E8%BD%BD%E8%BF%87%E9%AB%98%E6%8E%92%E6%9F%A5%E6%AD%A5%E9%AA%A4/","summary":"CPU 的使用会飙升，一旦飙升，一般怀疑某个业务逻辑的计算量太大，或者是触发了死循环（比如著名的 HashMap 高并发引起的死循环），也有可能是 GC 导致的，如：堆","title":"Java进程导致CPU负载过高排查步骤"},{"content":"最近工作需要用 Nacos 连接 Oracle 数据库，有两个方案，一个是使用最新版， 添加插件支持，还还一种是使用 Nacos 的多数据源分支，这个分支的 Nacos 版本是 1.4.2-SNAPSHOT，参考文章 ，坑就从这里开始了\u0026hellip;.\n1、故障现象 Error creating bean with name \u0026#39;jpaVendorAdapter\u0026#39; defined in class path resource [org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.orm.jpa.JpaVendorAdapter]: Factory method \u0026#39;jpaVendorAdapter\u0026#39; threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:361) at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:131) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1672) 2、导致原因 我的连接配置是：\nspring.jpa.hibernate.naming.physical-strategy=com.alibaba.nacos.config.server.configuration.NacosPhysicalNamingStrategy nacos.datasource.type=ORACLE nacos.datasource.relational.dsList[0].url=jdbc:oracle:thin:@localhost:1521:ORCL nacos.datasource.relational.dsList[0].username=nacos nacos.datasource.relational.dsList[0].password=123456 nacos.datasource.relational.dsList[0].driver-class-name=oracle.jdbc.driver.OracleDriver nacos.datasource.relational.dsList[0].hikari.connection-timeout=10000 nacos.datasource.relational.dsList[0].hikari.idle-timeout=120000 nacos.datasource.relational.dsList[0].hikari.max-lifetime=240000 nacos.datasource.relational.dsList[0].hikari.maximum-pool-size=20 nacos.datasource.relational.dsList[0].hikari.data-source-properties.cachePrepStmts=true nacos.datasource.relational.dsList[0].hikari.data-source-properties.prepStmtCacheSize=250 nacos.datasource.relational.dsList[0].hikari.data-source-properties.prepStmtCacheSqlLimit=2048 nacos.datasource.relational.dsList[0].hikari.connection-test-query=SELECT 1 FROM dual JVM启动参数设置为：-Dnacos.standalone=true\n点击运行 nacos-feature_multiple_datasource_support/console/src/main/java/com/alibaba/nacos/Nacos.java, 就出现了如上报错，一开始以为是我数据库版本的问题，因为提供的数据库表初始化脚本是12c的，而我安装的是19c,以为是版本不适配的缘故。我用 MySQL 连接的方式测试了一下发现程序可以正常启动，所以猜测问题应该出在连接驱动 Jar 包版本上，但搜索好几篇文章后发现驱动版本是正常的，所以排除，又怀疑问题出在数据库连接信息上，但仔细比对参考的那篇文档后发现并没有错误，于是Debug程序，发现异常是出在通过连接池获取数据库连接上，获取连接失败，但我用其他的数据库连接工具是可以连接上数据库的，于是可排除数据库本身的问题。\n后面想通过 JDBC 的方式测试一下，于是搜索了连接教程，发现 Oracle 的连接字符串还有好几种连接方式，有通过SID的，有通过服务名的，我最初看到的那篇教程是通过 SID 方式，但我的数据库配置的是通过服务名连接，于是修改连接字符串后程序就正常启动了。\nJDBC连接Oracle rac数据库的写法:\n格式一：jdbc:oracle:thin:@//:/\u0026lt;service_name\u0026gt; 格式二：jdbc:oracle:thin:@:: 格式三：jdbc:oracle:thin:@\n格式一是通过 SERVICE_NAME 连接Oracle数据库，适合于单实例和RAC\n格式二是通过实例名SID连接数据库，RAC环境下实例名不唯一，不能充分利用数据库资源\n格式三为通过本地配置的TNSNAME，支持RAC\n这个问题还是由于工作后没有接触过 Oracle 数据库，导致不熟悉出现此问题，特此记录下。\n3、解决方案 将连接 URL 改为：jdbc:oracle:thin:@//:/\u0026lt;service_name\u0026gt; 这种格式，注意这里的格式，port后面:换成了/,这种格式是Oracle 推荐的格式，因为对于集群来说，每个节点的SID 是不一样的，但是SERVICE_NAME 确可以包含所有节点。\n4、参考博客 Oracle JDBC 连接的几种方式\nnacos适配oracle数据库\n[nacos配置Oracle数据源](\n","permalink":"https://jiangjun8888.github.io/posts/tech/nacos%E8%BF%9E%E6%8E%A5oracle%E6%95%85%E9%9A%9C%E8%A7%A3%E5%86%B3/","summary":"最近工作需要用 Nacos 连接 Oracle 数据库，有两个方案，一个是使用最新版， 添加插件支持，还还一种是使用 Nacos 的多数据源分支，这个分支的 Nacos 版本是 1.4.2-SN","title":"Nacos连接Oracle故障解决"},{"content":" 转换符 详细说明 示例 %s 字符串类型 “喜欢请收藏” %c 字符类型 ‘m’ %b 布尔类型 true %d 整数类型（十进制） 88 %x 整数类型（十六进制） FF %o 整数类型（八进制） 77 %f 浮点类型 8.888 %a 十六进制浮点类型 FF.35AE %e 指数类型 9.38e+5 // 补齐空格并右对齐： String.format(\u0026#34;%10s, world\u0026#34;, \u0026#34;Hello\u0026#34;); // 输出 \u0026#34; Hello, world\u0026#34; String.format(\u0026#34;%8d\u0026#34;, 123); // 输出 \u0026#34; 123\u0026#34; // 补齐空格并左对齐： String.format(\u0026#34;%-10s, world\u0026#34;, \u0026#34;Hello\u0026#34;); // 输出 \u0026#34;Hello , world\u0026#34; String.format(\u0026#34;%-8d\u0026#34;, 123); // 输出 \u0026#34;123 \u0026#34; // 补齐 0 并对齐（仅对数字有效） String.format(\u0026#34;%08d\u0026#34;, 123); // 输出 \u0026#34;00000123\u0026#34; String.format(\u0026#34;%-08d\u0026#34;, 123); // 错误！不允许在右边补齐 0 // 输出最多N个字符 String.format(\u0026#34;%.5s\u0026#34;, \u0026#34;Hello, world\u0026#34;); // 输出 \u0026#34;Hello\u0026#34; String.format(\u0026#34;%.5s...\u0026#34;, \u0026#34;Hello, world\u0026#34;); // 输出 \u0026#34;Hello...\u0026#34; String.format(\u0026#34;%10.5s...\u0026#34;, \u0026#34;Hello, world\u0026#34;); // 输出 \u0026#34; Hello...\u0026#34; // 输出逗号分隔数字 String.format(\u0026#34;%,d\u0026#34;, 1234567); // 输出 \u0026#34;1,234,567\u0026#34; 搭配转换符还有实现高级功能\n标志 说明 示例 结果 + 为正数或者负数添加符号 (“%+d”,15) +15 0 数字前面补0(加密常用) (“%04d”, 99) 0099 空格 在整数之前添加指定数量的空格 (“% 4d”, 99) 99 , 以“,”对数字分组(常用显示金额) (“%,f”, 9999.99) 9,999.990000 - 左对齐，不够位数的地方补上空格 (\u0026quot;%-6d\u0026quot;,8) 8 ","permalink":"https://jiangjun8888.github.io/posts/tech/string.format%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","summary":"转换符 详细说明 示例 %s 字符串类型 “喜欢请收藏” %c 字符类型 ‘m’ %b 布尔类型 true %d 整数类型（十进制） 88 %x 整数类型（十六进制） FF %o 整数类型（八进制） 77","title":"String.format方法使用笔记"},{"content":"一、快速迁移方法 1、将 Jenkins 工作目录打包压缩。（因为 Jenkins 的所有配置都存放在工作目录下，所以我们迁移工作目录下的内容即可） 1.1、进入容器挂载的 Jenkins 工作目录，如果没有挂载，则进入容器，默认的工作目录是：/var/jenkins_home。此目录下又两个文件夹占用空间很大，为：./workspace 和 ./caches 第一个是保存的拉取下的代码和编译源文件，第二个是缓存文件，都可以删除掉已节省打包后的文件大小。保险起见先备份到另一个位置再删除。\n1.2、执行命令压缩目录\n#第一个参数为压缩后到文件名，第二个为你要压缩到目录所在位置 tar -cvf jenkins_home.tar /home/data/jenkins_home/ 2、将压缩包迁移至要部署的新机器中，我这用的 scp 命令 scp jenkins_home.tar root@IP地址:/root 1.会提示一段确认信息，输入yes后回车 2.提示输入目标机器登录密码，输入后回车 3、在新机器上启动一个全新的 Jenkins 容器，并挂载好工作目录 #我这是拉取的私人仓库的镜像，如果没有初始镜像的话，可以将最后的镜像名替换为：jenkins/jenkins:latest （来源：DockerHub） docker run -d --privileged=true \\ --name jenkins-hercules -p 8010:8080 -p 50000:50000 \\ --restart=always \\ -v /home/jenkins/data/jenkins_home:/var/jenkins_home \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /usr/bin/docker:/usr/bin/docker \\ -v /etc/localtime:/etc/localtime \\ --user root \\ jenkins-image 4、启动成功后停止容器，删除挂载的工作目录下的所有文件 rm -rf /home/jenkins/data/* 5、将原来压缩好的 Jenkins 工作目录解压至上一步容器挂载的工作目录下 cd /home/jenkins/data/ # 解压至当前目录下 tar -zxvf ~/jenkins_home.tar 6、启动刚刚停止的 Jenkins 容器，用户名和密码都还是原来的，至此迁移完成。 二、完整迁移方法（包含容器） 0、先将工作目录压缩后传到目标机器上，参照上方快速迁移方法的1、2步 1、查看容器运行状态 docker ps -a d796453c4ca1 jenkins:1.0 \u0026#34;/sbin/tini -- /usr/…\u0026#34; 11 months ago Up 6 hours 0.0.0.0:50000-\u0026gt;50000/tcp, :::50000-\u0026gt;50000/tcp, 0.0.0.0:8010-\u0026gt;8080/tcp, :::8010-\u0026gt;8080/tcp jenkins # ps:我这个容器是在在启动jenkins时就把工作目录挂载到宿主机上了，如果没有挂载，请进入容器，默认的工作目录是：/var/jenkins_home。 2、执行 docker commit 命令将容器保存为镜像 docker commit jenkins(容器名) jenkins-image(镜像名) 3、查看镜像 docker images REPOSITORY TAG IMAGE ID CREATED SIZE jenkins-image latest 4a12d5121f83 6 hours ago 3.59GB 4、将镜像保存为压缩文件 docker save docker save -o jenkins.tar（文件名） jenkins-image(镜像名) 5、将压缩好的tar文件移到新机器 #通过 scp 命令直接发送到新机器中，或者push 到 DockerHub 在 Pull到目标机器 #执行 docker load 将文件导入为镜像 docker load -i jenkins.tar（文件名） 6、创建 Jenkins 工作目录并赋予权限 mkdir -p /home/jenkins/data/jenkins_home/ #设置目录权限 chmod -R 777 /home/jenkins/ #给docker.sock授予权限 chmod 777 /var/run/docker.sock 7、执行命令启动 Jenkins docker run -d --privileged=true \\ --name jenkins-hercules -p 8010:8080 -p 50000:50000 \\ --restart=always \\ -v /home/jenkins/data/jenkins_home:/var/jenkins_home \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /usr/bin/docker:/usr/bin/docker \\ -v /etc/localtime:/etc/localtime \\ --user root \\ jenkins-image 8、参照上方快速迁移方法的4、5、6步将原来的工作目录替换掉现在的即可。 PS: 1、本来我认为保存了整个容器应该将原有的配置内容也都保存了，但启动后我访问 Jenkins 还是让我执行初始化的那些步骤，原来的配置都没了，暂时还没研究是什么原因导致，所以建议直接用快速迁移方法即可。\n2、如果你的 Jenkins 跑了很多流水线的话，实际上你要按照第二种方式备份你的镜像文件是巨大的，我这个将近 15GB 。通过删掉一些不必要的东西如：代码编译后的 Jar、缓存文件夹、maven仓库、npm软件包(前两个在工作目录下，后两个在容器的 root目录下，为隐藏文件夹，可通过 du -sh .[!.]* 显示隐藏目录)。清理后打包容器为镜像后还有 3.4G，如果服务器不是内网有带宽限制会导致文件传输巨慢，浪费时间。\n","permalink":"https://jiangjun8888.github.io/posts/tech/%E8%BF%81%E7%A7%BB%E5%A4%87%E4%BB%BDdocker%E4%B8%ADjenkins%E9%95%9C%E5%83%8F%E6%96%B9%E6%A1%88/","summary":"一、快速迁移方法 1、将 Jenkins 工作目录打包压缩。（因为 Jenkins 的所有配置都存放在工作目录下，所以我们迁移工作目录下的内容即可） 1.1、进入容器挂载的 Jenkins 工","title":"迁移备份Docker中Jenkins镜像方案"},{"content":"一、ES 是什么？ Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsearch 会集中存储您的数据，让您飞快完成搜索，微调相关性，进行强大的分析，并轻松缩放规模。\n​\t上述描述摘自官网，当你能看到我这篇文章的时候，脑海里应该对 ES 有一个初步的概念了，可以把它理解为把数据存放在内存中的 MySQL，它最主要的功能是海量数据实时检索，比起传统的关系型数据库的优点是，没有磁盘 IO 开销，因为索引数据大部分都是存在于内存中的，我们可以通过 ES 提供的 Rest API 像通过 SQL 语句查询关系型数据库中的数据一样，官方的描述是这种查询语言称为 DSL。\nElasticsearch 提供了一个完整的基于 JSON 的查询 DSL（领域特定语言）来定义查询。将查询 DSL 视为查询的 AST（抽象语法树），由两种类型的子句组成：\n叶查询子句 \u0026gt; \u0026gt; 叶查询子句在特定字段中查找特定值，例如 match,term或 range查询。这些查询可以自己使用。\n复合查询子句 \u0026gt; \u0026gt; 复合查询子句包装其他叶查询或复合查询，用于以逻辑方式组合多个查询（例如 boolordis_max查询），或改变它们的行为（例如 constant_scorequery）。\nDSL 使用文档 \u0026gt; \u0026gt; https://www.elastic.co/guide/en/elasticsearch/reference/7.17/query-dsl.html\n二、Kibana 是什么？ Kibana 使您能够塑造数据并在 Elastic Stack 中导航。使用 Kibana，您可以：\n搜索、观察和保护您的数据。 从发现文档到分析日志再到查找安全漏洞，Kibana 是您访问这些功能及更多功能的门户。 分析您的数据。 搜索隐藏的见解，可视化您在图表、仪表、地图、图形等中发现的内容，并将它们组合到仪表板中。 管理、监控和保护 Elastic Stack。 管理您的数据，监控 Elastic Stack 集群的健康状况，并控制哪些用户可以访问哪些功能。 Kibana 文档：https://www.elastic.co/guide/en/kibana/current/introduction.html ​\t可以将 Kibana 理解为方便我们发送 Rest API 请求的一个客户端，相当于专门为 ES 服务器打造的一个 Postman 。\n三、安装ES 、 Kibana ​\t安装前默认你的 Linux 已经具备了 docker、 docker-compose 环境，将下面的配置文件保存为名称是：docker-compose.yml 的文件。\nversion: \u0026#39;3.5\u0026#39; services: elasticsearch: container_name: elasticsearch build: context: services/elasticsearch args: - ES_VER=7.5.0 ports: - \u0026#34;9200:9200\u0026#34; - \u0026#34;9300:9300\u0026#34; environment: ES_JAVA_OPTS: \u0026#34;-Xms512m -Xmx512m\u0026#34; #设置使用jvm内存大小 discovery.type: single-node #以单一节点模式启动 # ELASTIC_PASSWORD: 123456 #设置ES密码 privileged: true volumes: - ./data/elasticsearch/plugins/:/usr/share/elasticsearch/plugins/ - ./data/elasticsearch/:/usr/share/elasticsearch/data/ - ./logs/elasticsearch/:/usr/share/elasticsearch/logs/ - ./services/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml kibana: container_name: kibana build: context: services/kibana args: - KIBANA_VER=7.5.0 ports: - \u0026#34;5601:5601\u0026#34; privileged: true volumes: - ./services/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml depends_on: - elasticsearch ​\t创建好文件后，在文件所属的目录下执行命令： docker-compose -f docker-compose.yml up -d （-d : 在后台所有启动服务, -f : 指定使用的Compose模板文件，默认为docker-compose.yml，可以多次指定。）我这里是安装的 7.5.0 的 ES 版本，Kibana 的版本与之对应，假设设置了 ES 密码，那么后续请求 ES 服务都需要带上身份验证信息，Kibana 也需要输入账户名、密码登录， 账户名默认为：elastic ，密码：yml 文件中设置的 ES 密码。\n四、向 ES 导入 Demo 数据 ​\t访问部署 Kibana 的机器, ip:5601，进入 Kibana 首页，点击网页做下架的展开菜单栏图标，选择 Dev Tools 选项，打开后，在网页左侧可以编写 DSL 语句，向 ES 发送请求，右侧显示相应结果。执行的命令如下,将内容粘贴至 Kibana中，将光标放置在 ：POST bank/_bulk 这一行，行尾右侧边栏回显示一个三角形和一个扳手图标，点击三角形发送请求保存数据。\nPOST bank/_bulk # 粘贴这个网页中的文档数据在下方然后点击执行（感谢此作者）：https://gitee.com/xlh_blog/common_content/blob/master/es%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE.json# 五、ES 入门测试 将以下文档创建名为：ES 7.5.postman_collection.json 的 JSON 文件，然后点击 Postman 左上角的 Import 按钮选中文件导入即可。\n{ \u0026#34;info\u0026#34;: { \u0026#34;_postman_id\u0026#34;: \u0026#34;34d02b44-25de-46e9-b4d2-c03f9e223ffd\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;ES 7.5\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;https://schema.getpostman.com/json/collection/v2.1.0/collection.json\u0026#34;, \u0026#34;_exporter_id\u0026#34;: \u0026#34;11045914\u0026#34; }, \u0026#34;item\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;查看版本\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34; } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;查看节点信息\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/_cat/nodes\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;_cat\u0026#34;, \u0026#34;nodes\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;查看主节点信息\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/_cat/master\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;_cat\u0026#34;, \u0026#34;master\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;查看所有索引\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/_cat/indices\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;_cat\u0026#34;, \u0026#34;indices\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;PUT指定ID保存\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;PUT\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;body\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;raw\u0026#34;, \u0026#34;raw\u0026#34;: \u0026#34;{\\n \\\u0026#34;name\\\u0026#34; : \\\u0026#34;jack\\\u0026#34;\\n}\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;raw\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;json\u0026#34; } } }, \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/1\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;1\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;POST保存\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;body\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;raw\u0026#34;, \u0026#34;raw\u0026#34;: \u0026#34;{\\n \\\u0026#34;name\\\u0026#34; : \\\u0026#34;jack1\\\u0026#34;\\n}\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;raw\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;json\u0026#34; } } }, \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/q1eYgIUBGSRCIL0j0d7A\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;q1eYgIUBGSRCIL0j0d7A\u0026#34; ] }, \u0026#34;description\u0026#34;: \u0026#34;可自动生成ID/指定ID相当于修改，PUT必须指定ID\u0026#34; }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;根据ID查询数据\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/1\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;1\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;删除指定ID数据\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;DELETE\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/1\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;1\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;删除索引\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;DELETE\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] } ] } 六、ES 基础请求 DSL 以下执行语句请在 Kibana 的 Dev Tools 中执行\n## 查询所有 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;sort\u0026#34;: [ { \u0026#34;account_number\u0026#34;: \u0026#34;desc\u0026#34; }, { \u0026#34;balance\u0026#34;: \u0026#34;asc\u0026#34; } ], \u0026#34;from\u0026#34;: 0, \u0026#34;size\u0026#34;: 20, \u0026#34;_source\u0026#34;: [\u0026#34;balance\u0026#34;,\u0026#34;firstname\u0026#34;] } ## 全文检索:会将查询条件分词，任意一个匹配都算匹配 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mail one\u0026#34; } } } ## 短语匹配：不会将查询条件分词，作为一个完整的词去搜索 ## 也可以使用字段.keyword 精确匹配，必须是值和搜索值完全相等 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_phrase\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mail one\u0026#34; } } } ## 多字段匹配,多个字段任意匹配,会分词查询 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;mill one\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;address\u0026#34;,\u0026#34;firstname\u0026#34;] } } } ## bool 复合查询，条件都要满足 and ## must:数组中的条件都要满足 must_not:都不满足 should == or 不是必须满足 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mill\u0026#34; } }, { \u0026#34;match_phrase\u0026#34;: { \u0026#34;firstname\u0026#34;: \u0026#34;mill\u0026#34; } } ], \u0026#34;must_not\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;abc\u0026#34; } } ], \u0026#34;should\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;FIELD\u0026#34;: \u0026#34;TEXT\u0026#34; } } ] } } } ## filter:筛选结果，不计算相关性得分 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;gte\u0026#34;: 10, \u0026#34;lte\u0026#34;: 20 } } } } } } ## 非文本字段检索推荐term GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;value\u0026#34;: 28 } } } } ## 搜索address中包含mi1l的所有人的年龄分布以及平均年龄 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mill\u0026#34; } }, \u0026#34;aggs\u0026#34;: { \u0026#34;ageAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34;, \u0026#34;size\u0026#34;: 10 } }, \u0026#34;ageAvg\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34; } } } } ## 按照年龄聚合，并且请求这些年龄段的这些人的平均薪资 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;aggs\u0026#34;: { \u0026#34;ageAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34; }, \u0026#34;aggs\u0026#34;: { \u0026#34;balanceAvg\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;balance\u0026#34; } } } } }, \u0026#34;size\u0026#34;: 0 } ## 查出所有年龄分布，并且这些年龄段中M的平均薪资和F的平均薪资以及这个年龄段的总体平均薪资 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;aggs\u0026#34;: { \u0026#34;ageAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34; }, \u0026#34;aggs\u0026#34;: { \u0026#34;balanceAvg\u0026#34; :{ \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;balance\u0026#34; } }, \u0026#34;genderAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;gender.keyword\u0026#34;, \u0026#34;size\u0026#34;: 10 }, \u0026#34;aggs\u0026#34;: { \u0026#34;genderBalanceAvg\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;balance\u0026#34; } } } } } } }, \u0026#34;size\u0026#34;: 0 } ## 新建索引时指定字段类型 PUT /my-index { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;email\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; } } } } ## 新建索引后添加字段映射，index:false 不参与搜索 PUT /my-index/_mapping { \u0026#34;properties\u0026#34; : { \u0026#34;id\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34;, \u0026#34;index\u0026#34; : false } } } ## 查看索引字段类型 GET my-index/_mapping ## es指定好映射规则后不允许修改，想要修改只能创建一个新的索引，然后把原有的数据迁移到新索引 GET bank/_mapping ## 创建新索引 指定映射关系 PUT /bank1/ { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34; : { \u0026#34;account_number\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34; }, \u0026#34;address\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34; }, \u0026#34;age\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34; }, \u0026#34;balance\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34; }, \u0026#34;city\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34; }, \u0026#34;email\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;employer\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;firstname\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;gender\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;lastname\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;state\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } } } } } ## 迁移数据到新索引中 POST _reindex { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;bank\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;account\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;bank1\u0026#34; } } GET /bank1/_search { \u0026#34;query\u0026#34; : { \u0026#34;match_all\u0026#34; :{} } } ## 使用默认分词器进行分词 （仅支持英文） POST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;加油努力.\u0026#34; } ## 使用IK分词器分词 ik_smart: 会做最粗粒度的拆分，适合 Phrase 查询。 POST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;加油努力.\u0026#34; } ## ik_max_word: 会将文本做最细粒度的拆分，会穷尽各种可能的组合，适合 Term Query； POST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;加油努力.\u0026#34; } ## 发起批量保存请求 POST my-index/_bulk {\u0026#34;index\u0026#34;:{\u0026#34;_id\u0026#34;:\u0026#34;1\u0026#34;}} {\u0026#34;age\u0026#34; : 1, \u0026#34;email\u0026#34; : \u0026#34;12345@qq.com\u0026#34;, \u0026#34;id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;张三\u0026#34;} {\u0026#34;index\u0026#34;:{\u0026#34;_id\u0026#34;:\u0026#34;2\u0026#34;}} {\u0026#34;age\u0026#34; : 21, \u0026#34;email\u0026#34; : \u0026#34;12345@qq.com\u0026#34;, \u0026#34;id\u0026#34; : \u0026#34;2\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;李四\u0026#34;} 七、相关文档链接 elasticsearch-analysis-ik ：IK分词器，安装了这个才支持对中文进行分词，下载与 ES 对应版本的 Releases 包，解压后放置在 ES 的 plugins 目录下重启 ES 即可。\nelasticsearch-head ：Elasticsearch 集群的可视化 Web 前端，相当于 Navicat 操作 MySQL。\nES 官方文档 ：英文好的同学可以直接翻阅官方文档学习 ES。\n","permalink":"https://jiangjun8888.github.io/posts/tech/elasticsearch%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","summary":"一、ES 是什么？ Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsear","title":"ElasticSearch基础入门教程"}]