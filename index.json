[{"content":"CPU 的使用会飙升，一旦飙升，一般怀疑某个业务逻辑的计算量太大，或者是触发了死循环（比如著名的 HashMap 高并发引起的死循环），也有可能是 GC 导致的，如：堆已经满了，但是又没有发生 OOM，于是 GC 进程就一直在那里回收，回收的效果又非常一般，造成 CPU 升高应用假死。\n（1）使用 top 命令，查找到使用 CPU 最多的某个进程，记录它的 pid。使用 Shift + P 快捷键可以按 CPU 的使用率进行排序。\ntop （2）再次使用 top 命令，加 -H 参数，查看某个进程中使用 CPU 最多的某个线程，记录线程的 ID。\ntop -Hp $pid （3）使用 printf 函数，将十进制的 tid 转化成十六进制。\nprintf %x $tid （4）使用 jstack 命令，查看 Java 进程的线程栈。\njstack $pid \u0026gt;$pid.log （5）使用 less 命令查看生成的文件，并查找刚才转化的十六进制 tid，找到发生问题的线程上下文。\nless $pid.log ","permalink":"https://jiangjun8888.github.io/posts/tech/java%E8%BF%9B%E7%A8%8B%E5%AF%BC%E8%87%B4cpu%E8%B4%9F%E8%BD%BD%E8%BF%87%E9%AB%98%E6%8E%92%E6%9F%A5%E6%AD%A5%E9%AA%A4/","summary":"CPU 的使用会飙升，一旦飙升，一般怀疑某个业务逻辑的计算量太大，或者是触发了死循环（比如著名的 HashMap 高并发引起的死循环），也有可能是 GC 导致的，如：堆","title":"Java进程导致CPU负载过高排查步骤"},{"content":"最近工作需要用 Nacos 连接 Oracle 数据库，有两个方案，一个是使用最新版， 添加插件支持，还还一种是使用 Nacos 的多数据源分支，这个分支的 Nacos 版本是 1.4.2-SNAPSHOT，参考文章 ，坑就从这里开始了\u0026hellip;.\n1、故障现象 Error creating bean with name \u0026#39;jpaVendorAdapter\u0026#39; defined in class path resource [org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.orm.jpa.JpaVendorAdapter]: Factory method \u0026#39;jpaVendorAdapter\u0026#39; threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:361) at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:131) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1672) 2、导致原因 我的连接配置是：\nspring.jpa.hibernate.naming.physical-strategy=com.alibaba.nacos.config.server.configuration.NacosPhysicalNamingStrategy nacos.datasource.type=ORACLE nacos.datasource.relational.dsList[0].url=jdbc:oracle:thin:@localhost:1521:ORCL nacos.datasource.relational.dsList[0].username=nacos nacos.datasource.relational.dsList[0].password=123456 nacos.datasource.relational.dsList[0].driver-class-name=oracle.jdbc.driver.OracleDriver nacos.datasource.relational.dsList[0].hikari.connection-timeout=10000 nacos.datasource.relational.dsList[0].hikari.idle-timeout=120000 nacos.datasource.relational.dsList[0].hikari.max-lifetime=240000 nacos.datasource.relational.dsList[0].hikari.maximum-pool-size=20 nacos.datasource.relational.dsList[0].hikari.data-source-properties.cachePrepStmts=true nacos.datasource.relational.dsList[0].hikari.data-source-properties.prepStmtCacheSize=250 nacos.datasource.relational.dsList[0].hikari.data-source-properties.prepStmtCacheSqlLimit=2048 nacos.datasource.relational.dsList[0].hikari.connection-test-query=SELECT 1 FROM dual JVM启动参数设置为：-Dnacos.standalone=true\n点击运行 nacos-feature_multiple_datasource_support/console/src/main/java/com/alibaba/nacos/Nacos.java, 就出现了如上报错，一开始以为是我数据库版本的问题，因为提供的数据库表初始化脚本是12c的，而我安装的是19c,以为是版本不适配的缘故。我用 MySQL 连接的方式测试了一下发现程序可以正常启动，所以猜测问题应该出在连接驱动 Jar 包版本上，但搜索好几篇文章后发现驱动版本是正常的，所以排除，又怀疑问题出在数据库连接信息上，但仔细比对参考的那篇文档后发现并没有错误，于是Debug程序，发现异常是出在通过连接池获取数据库连接上，获取连接失败，但我用其他的数据库连接工具是可以连接上数据库的，于是可排除数据库本身的问题。\n后面想通过 JDBC 的方式测试一下，于是搜索了连接教程，发现 Oracle 的连接字符串还有好几种连接方式，有通过SID的，有通过服务名的，我最初看到的那篇教程是通过 SID 方式，但我的数据库配置的是通过服务名连接，于是修改连接字符串后程序就正常启动了。\nJDBC连接Oracle rac数据库的写法:\n格式一：jdbc:oracle:thin:@//:/\u0026lt;service_name\u0026gt; 格式二：jdbc:oracle:thin:@:: 格式三：jdbc:oracle:thin:@\n格式一是通过 SERVICE_NAME 连接Oracle数据库，适合于单实例和RAC\n格式二是通过实例名SID连接数据库，RAC环境下实例名不唯一，不能充分利用数据库资源\n格式三为通过本地配置的TNSNAME，支持RAC\n这个问题还是由于工作后没有接触过 Oracle 数据库，导致不熟悉出现此问题，特此记录下。\n3、解决方案 将连接 URL 改为：jdbc:oracle:thin:@//:/\u0026lt;service_name\u0026gt; 这种格式，注意这里的格式，port后面:换成了/,这种格式是Oracle 推荐的格式，因为对于集群来说，每个节点的SID 是不一样的，但是SERVICE_NAME 确可以包含所有节点。\n4、参考博客 Oracle JDBC 连接的几种方式\nnacos适配oracle数据库\n[nacos配置Oracle数据源](\n","permalink":"https://jiangjun8888.github.io/posts/tech/nacos%E8%BF%9E%E6%8E%A5oracle%E6%95%85%E9%9A%9C%E8%A7%A3%E5%86%B3/","summary":"最近工作需要用 Nacos 连接 Oracle 数据库，有两个方案，一个是使用最新版， 添加插件支持，还还一种是使用 Nacos 的多数据源分支，这个分支的 Nacos 版本是 1.4.2-SN","title":"Nacos连接Oracle故障解决"},{"content":" 转换符 详细说明 示例 %s 字符串类型 “喜欢请收藏” %c 字符类型 ‘m’ %b 布尔类型 true %d 整数类型（十进制） 88 %x 整数类型（十六进制） FF %o 整数类型（八进制） 77 %f 浮点类型 8.888 %a 十六进制浮点类型 FF.35AE %e 指数类型 9.38e+5 // 补齐空格并右对齐： String.format(\u0026#34;%10s, world\u0026#34;, \u0026#34;Hello\u0026#34;); // 输出 \u0026#34; Hello, world\u0026#34; String.format(\u0026#34;%8d\u0026#34;, 123); // 输出 \u0026#34; 123\u0026#34; // 补齐空格并左对齐： String.format(\u0026#34;%-10s, world\u0026#34;, \u0026#34;Hello\u0026#34;); // 输出 \u0026#34;Hello , world\u0026#34; String.format(\u0026#34;%-8d\u0026#34;, 123); // 输出 \u0026#34;123 \u0026#34; // 补齐 0 并对齐（仅对数字有效） String.format(\u0026#34;%08d\u0026#34;, 123); // 输出 \u0026#34;00000123\u0026#34; String.format(\u0026#34;%-08d\u0026#34;, 123); // 错误！不允许在右边补齐 0 // 输出最多N个字符 String.format(\u0026#34;%.5s\u0026#34;, \u0026#34;Hello, world\u0026#34;); // 输出 \u0026#34;Hello\u0026#34; String.format(\u0026#34;%.5s...\u0026#34;, \u0026#34;Hello, world\u0026#34;); // 输出 \u0026#34;Hello...\u0026#34; String.format(\u0026#34;%10.5s...\u0026#34;, \u0026#34;Hello, world\u0026#34;); // 输出 \u0026#34; Hello...\u0026#34; // 输出逗号分隔数字 String.format(\u0026#34;%,d\u0026#34;, 1234567); // 输出 \u0026#34;1,234,567\u0026#34; 搭配转换符还有实现高级功能\n标志 说明 示例 结果 + 为正数或者负数添加符号 (“%+d”,15) +15 0 数字前面补0(加密常用) (“%04d”, 99) 0099 空格 在整数之前添加指定数量的空格 (“% 4d”, 99) 99 , 以“,”对数字分组(常用显示金额) (“%,f”, 9999.99) 9,999.990000 - 左对齐，不够位数的地方补上空格 (\u0026quot;%-6d\u0026quot;,8) 8 ","permalink":"https://jiangjun8888.github.io/posts/tech/string.format%E6%96%B9%E6%B3%95%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","summary":"转换符 详细说明 示例 %s 字符串类型 “喜欢请收藏” %c 字符类型 ‘m’ %b 布尔类型 true %d 整数类型（十进制） 88 %x 整数类型（十六进制） FF %o 整数类型（八进制） 77","title":"String.format方法使用笔记"},{"content":"一、快速迁移方法 1、将 Jenkins 工作目录打包压缩。（因为 Jenkins 的所有配置都存放在工作目录下，所以我们迁移工作目录下的内容即可） 1.1、进入容器挂载的 Jenkins 工作目录，如果没有挂载，则进入容器，默认的工作目录是：/var/jenkins_home。此目录下又两个文件夹占用空间很大，为：./workspace 和 ./caches 第一个是保存的拉取下的代码和编译源文件，第二个是缓存文件，都可以删除掉已节省打包后的文件大小。保险起见先备份到另一个位置再删除。\n1.2、执行命令压缩目录\n#第一个参数为压缩后到文件名，第二个为你要压缩到目录所在位置 tar -cvf jenkins_home.tar /home/data/jenkins_home/ 2、将压缩包迁移至要部署的新机器中，我这用的 scp 命令 scp jenkins_home.tar root@IP地址:/root 1.会提示一段确认信息，输入yes后回车 2.提示输入目标机器登录密码，输入后回车 3、在新机器上启动一个全新的 Jenkins 容器，并挂载好工作目录 #我这是拉取的私人仓库的镜像，如果没有初始镜像的话，可以将最后的镜像名替换为：jenkins/jenkins:latest （来源：DockerHub） docker run -d --privileged=true \\ --name jenkins-hercules -p 8010:8080 -p 50000:50000 \\ --restart=always \\ -v /home/jenkins/data/jenkins_home:/var/jenkins_home \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /usr/bin/docker:/usr/bin/docker \\ -v /etc/localtime:/etc/localtime \\ --user root \\ jenkins-image 4、启动成功后停止容器，删除挂载的工作目录下的所有文件 rm -rf /home/jenkins/data/* 5、将原来压缩好的 Jenkins 工作目录解压至上一步容器挂载的工作目录下 cd /home/jenkins/data/ # 解压至当前目录下 tar -zxvf ~/jenkins_home.tar 6、启动刚刚停止的 Jenkins 容器，用户名和密码都还是原来的，至此迁移完成。 二、完整迁移方法（包含容器） 0、先将工作目录压缩后传到目标机器上，参照上方快速迁移方法的1、2步 1、查看容器运行状态 docker ps -a d796453c4ca1 jenkins:1.0 \u0026#34;/sbin/tini -- /usr/…\u0026#34; 11 months ago Up 6 hours 0.0.0.0:50000-\u0026gt;50000/tcp, :::50000-\u0026gt;50000/tcp, 0.0.0.0:8010-\u0026gt;8080/tcp, :::8010-\u0026gt;8080/tcp jenkins # ps:我这个容器是在在启动jenkins时就把工作目录挂载到宿主机上了，如果没有挂载，请进入容器，默认的工作目录是：/var/jenkins_home。 2、执行 docker commit 命令将容器保存为镜像 docker commit jenkins(容器名) jenkins-image(镜像名) 3、查看镜像 docker images REPOSITORY TAG IMAGE ID CREATED SIZE jenkins-image latest 4a12d5121f83 6 hours ago 3.59GB 4、将镜像保存为压缩文件 docker save docker save -o jenkins.tar（文件名） jenkins-image(镜像名) 5、将压缩好的tar文件移到新机器 #通过 scp 命令直接发送到新机器中，或者push 到 DockerHub 在 Pull到目标机器 #执行 docker load 将文件导入为镜像 docker load -i jenkins.tar（文件名） 6、创建 Jenkins 工作目录并赋予权限 mkdir -p /home/jenkins/data/jenkins_home/ #设置目录权限 chmod -R 777 /home/jenkins/ #给docker.sock授予权限 chmod 777 /var/run/docker.sock 7、执行命令启动 Jenkins docker run -d --privileged=true \\ --name jenkins-hercules -p 8010:8080 -p 50000:50000 \\ --restart=always \\ -v /home/jenkins/data/jenkins_home:/var/jenkins_home \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /usr/bin/docker:/usr/bin/docker \\ -v /etc/localtime:/etc/localtime \\ --user root \\ jenkins-image 8、参照上方快速迁移方法的4、5、6步将原来的工作目录替换掉现在的即可。 PS: 1、本来我认为保存了整个容器应该将原有的配置内容也都保存了，但启动后我访问 Jenkins 还是让我执行初始化的那些步骤，原来的配置都没了，暂时还没研究是什么原因导致，所以建议直接用快速迁移方法即可。\n2、如果你的 Jenkins 跑了很多流水线的话，实际上你要按照第二种方式备份你的镜像文件是巨大的，我这个将近 15GB 。通过删掉一些不必要的东西如：代码编译后的 Jar、缓存文件夹、maven仓库、npm软件包(前两个在工作目录下，后两个在容器的 root目录下，为隐藏文件夹，可通过 du -sh .[!.]* 显示隐藏目录)。清理后打包容器为镜像后还有 3.4G，如果服务器不是内网有带宽限制会导致文件传输巨慢，浪费时间。\n","permalink":"https://jiangjun8888.github.io/posts/tech/%E8%BF%81%E7%A7%BB%E5%A4%87%E4%BB%BDdocker%E4%B8%ADjenkins%E9%95%9C%E5%83%8F%E6%96%B9%E6%A1%88/","summary":"一、快速迁移方法 1、将 Jenkins 工作目录打包压缩。（因为 Jenkins 的所有配置都存放在工作目录下，所以我们迁移工作目录下的内容即可） 1.1、进入容器挂载的 Jenkins 工","title":"迁移备份Docker中Jenkins镜像方案"},{"content":"一、ES 是什么？ Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsearch 会集中存储您的数据，让您飞快完成搜索，微调相关性，进行强大的分析，并轻松缩放规模。\n​\t上述描述摘自官网，当你能看到我这篇文章的时候，脑海里应该对 ES 有一个初步的概念了，可以把它理解为把数据存放在内存中的 MySQL，它最主要的功能是海量数据实时检索，比起传统的关系型数据库的优点是，没有磁盘 IO 开销，因为索引数据大部分都是存在于内存中的，我们可以通过 ES 提供的 Rest API 像通过 SQL 语句查询关系型数据库中的数据一样，官方的描述是这种查询语言称为 DSL。\nElasticsearch 提供了一个完整的基于 JSON 的查询 DSL（领域特定语言）来定义查询。将查询 DSL 视为查询的 AST（抽象语法树），由两种类型的子句组成：\n叶查询子句 \u0026gt; \u0026gt; 叶查询子句在特定字段中查找特定值，例如 match,term或 range查询。这些查询可以自己使用。\n复合查询子句 \u0026gt; \u0026gt; 复合查询子句包装其他叶查询或复合查询，用于以逻辑方式组合多个查询（例如 boolordis_max查询），或改变它们的行为（例如 constant_scorequery）。\nDSL 使用文档 \u0026gt; \u0026gt; https://www.elastic.co/guide/en/elasticsearch/reference/7.17/query-dsl.html\n二、Kibana 是什么？ Kibana 使您能够塑造数据并在 Elastic Stack 中导航。使用 Kibana，您可以：\n搜索、观察和保护您的数据。 从发现文档到分析日志再到查找安全漏洞，Kibana 是您访问这些功能及更多功能的门户。 分析您的数据。 搜索隐藏的见解，可视化您在图表、仪表、地图、图形等中发现的内容，并将它们组合到仪表板中。 管理、监控和保护 Elastic Stack。 管理您的数据，监控 Elastic Stack 集群的健康状况，并控制哪些用户可以访问哪些功能。 Kibana 文档：https://www.elastic.co/guide/en/kibana/current/introduction.html ​\t可以将 Kibana 理解为方便我们发送 Rest API 请求的一个客户端，相当于专门为 ES 服务器打造的一个 Postman 。\n三、安装ES 、 Kibana ​\t安装前默认你的 Linux 已经具备了 docker、 docker-compose 环境，将下面的配置文件保存为名称是：docker-compose.yml 的文件。\nversion: \u0026#39;3.5\u0026#39; services: elasticsearch: container_name: elasticsearch build: context: services/elasticsearch args: - ES_VER=7.5.0 ports: - \u0026#34;9200:9200\u0026#34; - \u0026#34;9300:9300\u0026#34; environment: ES_JAVA_OPTS: \u0026#34;-Xms512m -Xmx512m\u0026#34; #设置使用jvm内存大小 discovery.type: single-node #以单一节点模式启动 # ELASTIC_PASSWORD: 123456 #设置ES密码 privileged: true volumes: - ./data/elasticsearch/plugins/:/usr/share/elasticsearch/plugins/ - ./data/elasticsearch/:/usr/share/elasticsearch/data/ - ./logs/elasticsearch/:/usr/share/elasticsearch/logs/ - ./services/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml kibana: container_name: kibana build: context: services/kibana args: - KIBANA_VER=7.5.0 ports: - \u0026#34;5601:5601\u0026#34; privileged: true volumes: - ./services/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml depends_on: - elasticsearch ​\t创建好文件后，在文件所属的目录下执行命令： docker-compose -f docker-compose.yml up -d （-d : 在后台所有启动服务, -f : 指定使用的Compose模板文件，默认为docker-compose.yml，可以多次指定。）我这里是安装的 7.5.0 的 ES 版本，Kibana 的版本与之对应，假设设置了 ES 密码，那么后续请求 ES 服务都需要带上身份验证信息，Kibana 也需要输入账户名、密码登录， 账户名默认为：elastic ，密码：yml 文件中设置的 ES 密码。\n四、向 ES 导入 Demo 数据 ​\t访问部署 Kibana 的机器, ip:5601，进入 Kibana 首页，点击网页做下架的展开菜单栏图标，选择 Dev Tools 选项，打开后，在网页左侧可以编写 DSL 语句，向 ES 发送请求，右侧显示相应结果。执行的命令如下,将内容粘贴至 Kibana中，将光标放置在 ：POST bank/_bulk 这一行，行尾右侧边栏回显示一个三角形和一个扳手图标，点击三角形发送请求保存数据。\nPOST bank/_bulk # 粘贴这个网页中的文档数据在下方然后点击执行（感谢此作者）：https://gitee.com/xlh_blog/common_content/blob/master/es%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE.json# 五、ES 入门测试 将以下文档创建名为：ES 7.5.postman_collection.json 的 JSON 文件，然后点击 Postman 左上角的 Import 按钮选中文件导入即可。\n{ \u0026#34;info\u0026#34;: { \u0026#34;_postman_id\u0026#34;: \u0026#34;34d02b44-25de-46e9-b4d2-c03f9e223ffd\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;ES 7.5\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;https://schema.getpostman.com/json/collection/v2.1.0/collection.json\u0026#34;, \u0026#34;_exporter_id\u0026#34;: \u0026#34;11045914\u0026#34; }, \u0026#34;item\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;查看版本\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34; } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;查看节点信息\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/_cat/nodes\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;_cat\u0026#34;, \u0026#34;nodes\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;查看主节点信息\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/_cat/master\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;_cat\u0026#34;, \u0026#34;master\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;查看所有索引\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/_cat/indices\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;_cat\u0026#34;, \u0026#34;indices\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;PUT指定ID保存\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;PUT\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;body\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;raw\u0026#34;, \u0026#34;raw\u0026#34;: \u0026#34;{\\n \\\u0026#34;name\\\u0026#34; : \\\u0026#34;jack\\\u0026#34;\\n}\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;raw\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;json\u0026#34; } } }, \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/1\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;1\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;POST保存\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;body\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;raw\u0026#34;, \u0026#34;raw\u0026#34;: \u0026#34;{\\n \\\u0026#34;name\\\u0026#34; : \\\u0026#34;jack1\\\u0026#34;\\n}\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;raw\u0026#34;: { \u0026#34;language\u0026#34;: \u0026#34;json\u0026#34; } } }, \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/q1eYgIUBGSRCIL0j0d7A\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;q1eYgIUBGSRCIL0j0d7A\u0026#34; ] }, \u0026#34;description\u0026#34;: \u0026#34;可自动生成ID/指定ID相当于修改，PUT必须指定ID\u0026#34; }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;根据ID查询数据\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/1\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;1\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;删除指定ID数据\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;DELETE\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student/one/1\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34;, \u0026#34;one\u0026#34;, \u0026#34;1\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] }, { \u0026#34;name\u0026#34;: \u0026#34;删除索引\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;DELETE\u0026#34;, \u0026#34;header\u0026#34;: [], \u0026#34;url\u0026#34;: { \u0026#34;raw\u0026#34;: \u0026#34;http://localhost:9200/student\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;host\u0026#34;: [ \u0026#34;localhost\u0026#34; ], \u0026#34;port\u0026#34;: \u0026#34;9200\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;student\u0026#34; ] } }, \u0026#34;response\u0026#34;: [] } ] } 六、ES 基础请求 DSL 以下执行语句请在 Kibana 的 Dev Tools 中执行\n## 查询所有 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;sort\u0026#34;: [ { \u0026#34;account_number\u0026#34;: \u0026#34;desc\u0026#34; }, { \u0026#34;balance\u0026#34;: \u0026#34;asc\u0026#34; } ], \u0026#34;from\u0026#34;: 0, \u0026#34;size\u0026#34;: 20, \u0026#34;_source\u0026#34;: [\u0026#34;balance\u0026#34;,\u0026#34;firstname\u0026#34;] } ## 全文检索:会将查询条件分词，任意一个匹配都算匹配 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mail one\u0026#34; } } } ## 短语匹配：不会将查询条件分词，作为一个完整的词去搜索 ## 也可以使用字段.keyword 精确匹配，必须是值和搜索值完全相等 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_phrase\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mail one\u0026#34; } } } ## 多字段匹配,多个字段任意匹配,会分词查询 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;mill one\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;address\u0026#34;,\u0026#34;firstname\u0026#34;] } } } ## bool 复合查询，条件都要满足 and ## must:数组中的条件都要满足 must_not:都不满足 should == or 不是必须满足 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mill\u0026#34; } }, { \u0026#34;match_phrase\u0026#34;: { \u0026#34;firstname\u0026#34;: \u0026#34;mill\u0026#34; } } ], \u0026#34;must_not\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;abc\u0026#34; } } ], \u0026#34;should\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;FIELD\u0026#34;: \u0026#34;TEXT\u0026#34; } } ] } } } ## filter:筛选结果，不计算相关性得分 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;gte\u0026#34;: 10, \u0026#34;lte\u0026#34;: 20 } } } } } } ## 非文本字段检索推荐term GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;value\u0026#34;: 28 } } } } ## 搜索address中包含mi1l的所有人的年龄分布以及平均年龄 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;mill\u0026#34; } }, \u0026#34;aggs\u0026#34;: { \u0026#34;ageAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34;, \u0026#34;size\u0026#34;: 10 } }, \u0026#34;ageAvg\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34; } } } } ## 按照年龄聚合，并且请求这些年龄段的这些人的平均薪资 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;aggs\u0026#34;: { \u0026#34;ageAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34; }, \u0026#34;aggs\u0026#34;: { \u0026#34;balanceAvg\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;balance\u0026#34; } } } } }, \u0026#34;size\u0026#34;: 0 } ## 查出所有年龄分布，并且这些年龄段中M的平均薪资和F的平均薪资以及这个年龄段的总体平均薪资 GET bank/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;aggs\u0026#34;: { \u0026#34;ageAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;age\u0026#34; }, \u0026#34;aggs\u0026#34;: { \u0026#34;balanceAvg\u0026#34; :{ \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;balance\u0026#34; } }, \u0026#34;genderAgg\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;gender.keyword\u0026#34;, \u0026#34;size\u0026#34;: 10 }, \u0026#34;aggs\u0026#34;: { \u0026#34;genderBalanceAvg\u0026#34;: { \u0026#34;avg\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;balance\u0026#34; } } } } } } }, \u0026#34;size\u0026#34;: 0 } ## 新建索引时指定字段类型 PUT /my-index { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;email\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; } } } } ## 新建索引后添加字段映射，index:false 不参与搜索 PUT /my-index/_mapping { \u0026#34;properties\u0026#34; : { \u0026#34;id\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34;, \u0026#34;index\u0026#34; : false } } } ## 查看索引字段类型 GET my-index/_mapping ## es指定好映射规则后不允许修改，想要修改只能创建一个新的索引，然后把原有的数据迁移到新索引 GET bank/_mapping ## 创建新索引 指定映射关系 PUT /bank1/ { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34; : { \u0026#34;account_number\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34; }, \u0026#34;address\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34; }, \u0026#34;age\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34; }, \u0026#34;balance\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;long\u0026#34; }, \u0026#34;city\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34; }, \u0026#34;email\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;employer\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;firstname\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;gender\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;lastname\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } }, \u0026#34;state\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;text\u0026#34;, \u0026#34;fields\u0026#34; : { \u0026#34;keyword\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;, \u0026#34;ignore_above\u0026#34; : 256 } } } } } } ## 迁移数据到新索引中 POST _reindex { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;bank\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;account\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;bank1\u0026#34; } } GET /bank1/_search { \u0026#34;query\u0026#34; : { \u0026#34;match_all\u0026#34; :{} } } ## 使用默认分词器进行分词 （仅支持英文） POST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;加油努力.\u0026#34; } ## 使用IK分词器分词 ik_smart: 会做最粗粒度的拆分，适合 Phrase 查询。 POST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;加油努力.\u0026#34; } ## ik_max_word: 会将文本做最细粒度的拆分，会穷尽各种可能的组合，适合 Term Query； POST _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;加油努力.\u0026#34; } ## 发起批量保存请求 POST my-index/_bulk {\u0026#34;index\u0026#34;:{\u0026#34;_id\u0026#34;:\u0026#34;1\u0026#34;}} {\u0026#34;age\u0026#34; : 1, \u0026#34;email\u0026#34; : \u0026#34;12345@qq.com\u0026#34;, \u0026#34;id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;张三\u0026#34;} {\u0026#34;index\u0026#34;:{\u0026#34;_id\u0026#34;:\u0026#34;2\u0026#34;}} {\u0026#34;age\u0026#34; : 21, \u0026#34;email\u0026#34; : \u0026#34;12345@qq.com\u0026#34;, \u0026#34;id\u0026#34; : \u0026#34;2\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;李四\u0026#34;} 七、相关文档链接 elasticsearch-analysis-ik ：IK分词器，安装了这个才支持对中文进行分词，下载与 ES 对应版本的 Releases 包，解压后放置在 ES 的 plugins 目录下重启 ES 即可。\nelasticsearch-head ：Elasticsearch 集群的可视化 Web 前端，相当于 Navicat 操作 MySQL。\nES 官方文档 ：英文好的同学可以直接翻阅官方文档学习 ES。\n","permalink":"https://jiangjun8888.github.io/posts/tech/elasticsearch%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","summary":"一、ES 是什么？ Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsear","title":"ElasticSearch基础入门教程"}]